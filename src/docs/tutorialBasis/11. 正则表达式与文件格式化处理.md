# 正则表达式与文件格式化处理
正则表达式（Regular Expression ）是通过一些特殊字符的排列，用来搜索或替换、删除一列或多列文字字符串

本章需要多练习：因为目前很多套件都使用正则表达式来达成过来、分析的目的，为了未来主机管理的便利性，使用者至少要能看懂正则表达式的含义

## 开始之前：上面是正则表达式
- 什么是正则表达式：

  这个就不解释了，某些指令支持，比如 `grep 'mail' /lib/systemd/system/*` 搜索该目录下的所有文件中包含 mail 的文件，但是 cp ls 等命令不支持正则表达式，只能使用 bash 自己本身的通配符
  
- 正则表达式对于系统管理员的用途

  对于一般使用者来说，使用不多，对于系统管理员来说，是必学的知识，如 错误信息登录文件（第十八章中）的内容记录了系统产生的所有信息，包含是否被入侵的记录数据，可以通过正则表达式将这些登录信息进行处理，仅取出有问题的信息进行分析

- 正则表达式的广泛用途

  由于正则表达式强大的字符串处理能力，一堆软件都支持

- 正则表达式与 shell 在 Linux 中的角色定位

  这样说吧，小学的 九九乘法表 有多重要，shell 与 正则表达式就有多重要

- 扩展的正则表达式

  正则表达式的字符串表示方式依照不同的严谨程度分为：基础正则表达式、扩展正则表达式。

  
## 基础正则表达式

既然正则表达式是处理字符串的一种表示方式，那么对字符排序有影响的语系数据就会对正则表达式的结果有影响。此外也需要有支持工具程序来辅助才行。

因此这里先介绍一个最简单的字符串摘取工具程序 grep。前面讲解了 grep 的相关参数与参数，本章着重讲解进阶的 grep 选项说明，介绍完 grep 的功能后，就进入正则表达式的特殊字符处理能力

## 语系对正则表达式的影响

为什么语系数据会影响正则表达式的输出结果？在第 0 章计算器概论的文字编码系统里面谈到，文件其实记录的仅有 0 与 1，我们看到的字符与数值都是通过编码表转换来的。

由于不同语系的编码数据不同，就会造成数据处理结果的差异了，举例说明，假设两种语系输出结果为：

- LANG=C：0 1 2 3 ... A B C D ..Z a b c d .. z
- LANG=zh_TW ：0 1 2 3 ... a A b c C D .. z Z

两种语系明显不一样，如果想获取大写字符使用 `[A-Z]`时，会发现 C 可以获取到正确的大写字符（因为是连续的），zh_TW 连同小写也会 b-z 也会获取到，因为就编码的顺序来看，big5 语系可以获取到 `A b B c C .. z Z` 这一堆字符。

所以使用正则表达式时，需要留意当前的语系，否则可能发现与别人不同的截取结果

由于一般我们再联系正则表达式时，使用的是兼容于 POSIX 的标准，因此就使用 C 这个语系，因此下面的练习都是使用 `LANG=C`来练习的。为了避免这样编码所造成的英文与数字截取问题，因此特殊符号需要了解下

- `[:alnum:]`：代表英文大小写字符及数字，即 0-9、A-Z、a-z
- `[:alpha:]`：代表任何英文大小写字符，A-Z、a-z
- `[:blank:]`：代表空格与 tab
- `[:cntrl:]`：代表键盘上面的控制按键，包括 CR、LF、TAB、Del 等
- `[:digit:]`：代表数字，0-9
- `[:graph:]`：除了空格符（空格键与 tab 键）外其他的所有按键
- `[:lower:]`：代表些小字符，a-z
- `[:print:]`：代表任何可以被打印出来的字符
- `[:punct:]`：代表标点符号（punctuation symbol）
- `[:upper:]`：代表大写字符，A-Z
- `[:space:]`：任何会产生空白的字符，包括空格、tab、CR 等
- `[:xdigit:]`：代表 16 进制的数值类型，包括 0-9、A-F、a-f 的数字与字符

尤其是 ``[:alnum:]``、`[:alpha:]`、`[:upper:]`、`[:lower:]`、`[:digit:]`一定要知道代表什么意思，因为他们要比 a-z 或 A-Z 的用途要确定。

## grep 的一些进阶选项

在第十章 BASH 中的 grep 谈论过一些基础用法，下面列出较进阶的 grep 选项与参数

```bash
grep [-A] [-B] [--color='auto'] '关键词' filename

-A：后面可以加数字，为 after 的意思，除了列出该行外，后续的 n 行也列出来
-B：后面可以加数字，为 befer 的意思，处理列出该行外，前面的 n 行也列出来
--colort=auto：可将正确的哪个截取数据列出颜色
```

实践与练习

```bash
# 范例 1：用 dmesg 列出核心信息，再以 grep 找出含有 qx1 那一行
dmesg | grep 'qx1'
# 笔者不知道自己使用的显卡是什么，而且使用的是虚拟机，而作者使用的显卡是 qx1，所以查看显卡信息

# 范例 2：用 --color=auto 显示查找到的关键词高亮,并显示行号
dmesg | grep -n --color=auto ‘qx1’

# 范例 3：在关键词所在行的前两行与后三行也一起显示出来
dmest | grep -n -A2 -B3 --color=auto 'qx1'
```

grep 是一个很常见也很常用的指令，最重要的功能就是进行字符串的比对，然后将符合用户需求的字符串打印出来。需要注意的是：grep 是已整行为单位来进行数据截取的

## 基础正则表达式练习

要了解正则表达式最简单的方法就是由实际练习去感受，所以在汇总特殊符号前，先以下面这个文件的内容来进行正则表达式的练习，练习前提为：

- 语系已经使用 `export LANG=C；export LC_ALL=C`
- grep 已经使用 alias 设置为 `grep --color=auto`

本机默认为 `LANG=en_US.UTF-8;LC_ALL=`

文件为 regular——express.txt ，该文件内容是在 windows 系统下编辑的，所以包含 dos 的换行符；

```
"Open Source" is a good mechanism to develop programs.
apple is my favorite food.
Football game is not use feet only.
this dress doesn't fit me.
However, this dress is about $ 3183 dollars.
GNU is free air not free beer.
Her hair is very beauty.
I can't finish the test.
Oh! The soup taste good.
motorcycle is cheap than car.
This window is clear.
the symbol '*' is represented as start.
Oh!	My god!
The gd software is a library for drafting programs.
You are the best is mean you are the no. 1.
The world <Happy> is the same with "glad".
I like dog.
google is the best tools for search keyword.
goooooogle yes!
go! go! Let's go.
# I am VBird

```

文件最后一行为空白行。

### 范例 1：搜索特定字符

从文件中取得 the 这个特定字符串，最简单的方式如下

```bash
[mrcode@study tmp]$ grep -n 'the' regular_express.txt
8:I can't finish the test.
12:the symbol '*' is represented as start.
15:You are the best is mean you are the no. 1.
16:The world <Happy> is the same with "glad".
18:google is the best tools for search keyword.
```

反向选择，可以看到输出结果少了上面的 8、12、15、16、18 行

```bash
[mrcode@study tmp]$ grep -vn 'the' regular_express.txt
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
4:this dress doesn't fit me.
5:However, this dress is about $ 3183 dollars.
6:GNU is free air not free beer.
7:Her hair is very beauty.
9:Oh! The soup taste good.
10:motorcycle is cheap than car.
11:This window is clear.
13:Oh!  My god!
14:The gd software is a library for drafting programs.
17:I like dog.
19:goooooogle yes!
20:go! go! Let's go.
21:# I am VBird
22:
```

忽略大小写 ，多出来几行

```bash
[mrcode@study tmp]$ grep -in 'the' regular_express.txt
8:I can't finish the test.
9:Oh! The soup taste good.
12:the symbol '*' is represented as start.
14:The gd software is a library for drafting programs.
15:You are the best is mean you are the no. 1.
16:The world <Happy> is the same with "glad".
18:google is the best tools for search keyword.
```

### 范例 2：利用中括号`[]`来搜索集合字符

如果要搜索 test 或 taste 这两个单词时，可以发现他们其实有共同的 `t?st` 存在

```
[mrcode@study tmp]$ grep -n 't[ae]st' regular_express.txt
8:I can't finish the test.
9:Oh! The soup taste good.
```

中括号中，无论几个字符都表示任意一个字符。如果想要搜索到所有 oo 字符时

```bash
[mrcode@study tmp]$ grep -n 'oo' regular_express.txt
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
9:Oh! The soup taste good.
18:google is the best tools for search keyword.
19:goooooogle yes!
```

如果不想要 oo 前面的 g 呢？

```bash
[mrcode@study tmp]$ grep -n '[^g]oo' regular_express.txt
2:apple is my favorite food.
3:Football game is not use feet only.
18:google is the best tools for search keyword.
19:goooooogle yes!
```

会发现可能会有一部分是正确的，一部分是错误的，比如 1、9 行少了，但是 google 和 goooooogle 还是出来了，是怎么回事？第 18 行，出现了 tools 所以也符合 `[^g]oo`，而 19 行，中间有那么多的 oo，也符合

继续，不想要 oo 前面是小写字符的

```bash
# 由于小写字符的 ASCII 编码顺序是连续的，所以可以简化为，否则就需要把 a-z 都写出来
[mrcode@study tmp]$ grep -n '[^a-z]oo' regular_express.txt
3:Football game is not use feet only.

# 取得有数字那一行
[mrcode@study tmp]$ grep -n '[0-9]' regular_express.txt
5:However, this dress is about $ 3183 dollars.
15:You are the best is mean you are the no. 1.
```

由于考虑到语系对于编码顺序的影响，因此除了连续编码使用减号 `-`，还可以使用如下的方法来取得前面两个测试的结果

```bash
[mrcode@study tmp]$ grep -n '[^[:lower:]]oo' regular_express.txt
3:Football game is not use feet only.

[mrcode@study tmp]$ grep -n '[[:digit:]]' regular_express.txt
5:However, this dress is about $ 3183 dollars.
15:You are the best is mean you are the no. 1.
```

### 范例 3：行首与行位字符 `^、$`

```bash
# 只要行首是 the 的
[mrcode@study tmp]$ grep -n '^the' regular_express.txt 
12:the symbol '*' is represented as start.

# 想要行首是小写字符开头的
[mrcode@study tmp]$ grep -n '^[a-z]' regular_express.txt 
2:apple is my favorite food.
4:this dress doesn't fit me.
10:motorcycle is cheap than car.
12:the symbol '*' is represented as start.
18:google is the best tools for search keyword.
19:goooooogle yes!
20:go! go! Let's go.
# 下面的等效
# [mrcode@study tmp]$ grep -n '^[[:lower:]]' regular_express.txt 

# 不要英文字母开头的
# ^ 在中括号内表示反选，在外表示定位首航
[mrcode@study tmp]$ grep -n '^[^a-zA-Z]' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
21:# I am VBird
```

行尾练习

```bash
# 找出行尾为 . 符号的数据
# 使用 \ 对 小数点转义
[mrcode@study tmp]$ grep -n '\.$' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
4:this dress doesn't fit me.
5:However, this dress is about $ 3183 dollars.
6:GNU is free air not free beer.
7:Her hair is very beauty.
8:I can't finish the test.
9:Oh! The soup taste good.
10:motorcycle is cheap than car.
11:This window is clear.
12:the symbol '*' is represented as start.
14:The gd software is a library for drafting programs.
15:You are the best is mean you are the no. 1.
16:The world <Happy> is the same with "glad".
17:I like dog.
18:google is the best tools for search keyword.
20:go! go! Let's go.

```

这里需要说一句，原本的文件 5-9 行默认是 `.^M$` 结尾的，也就是 `\r\n`，由于没有网络，无法下载文件，所以复制粘贴丢失了这些换行符，和书上结果不一样。

也就是说上面的示例 5-9 不应该出来的，使用命令查看特殊字符应该如下

```bash
[mrcode@study tmp]$ cat -An regular_express.txt | head -n 10 | tail -n 6
     5  However, this dress is about $ 3183 dollars.^M$
     6  GNU is free air not free beer.^M$
     7  Her hair is very beauty.^M$
     8  I can't finish the test.^M$
     9  Oh! The soup taste good.^M$
    10  motorcycle is cheap than car.$		# 但实际上 ^M 被丢失了

```

找出空白行

```bash
[mrcode@study tmp]$ grep -n '^$' regular_express.txt 
22:
# 只有行首和行尾的表示法，中间没有任何字符，所以是 ^$
```

假设你已经知道 shell script 或则是配置文件中，空白行与开头为 # 的那一行是批注，想要将这些数据忽略掉，该怎么做？

```bash
[mrcode@study tmp]$ cat -n /etc/rsyslog.conf 
# 在 centOS 7 中可以看到有 91 行，有大量的空行与批注信息

# 第一种写法：-v '^$' 是反选，也就是排除空行的，-v ‘^#’ 排除开头是 # 号的
# 但是这里的行号与源文件对不上了，后面的行号是针对前面排除空行后的行号
[mrcode@study tmp]$ grep -v '^$' /etc/rsyslog.conf | grep -vn '^#'
6:$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)
7:$ModLoad imjournal # provides access to the systemd journal
18:$WorkDirectory /var/lib/rsyslog
20:$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat
25:$IncludeConfig /etc/rsyslog.d/*.conf
28:$OmitLocalLogging on
30:$IMJournalStateFile imjournal.state
37:*.info;mail.none;authpriv.none;cron.none                /var/log/messages
39:authpriv.*                                              /var/log/secure
41:mail.*                                                  -/var/log/maillog
43:cron.*                                                  /var/log/cron
45:*.emerg                                                 :omusrmsg:*
47:uucp,news.crit                                          /var/log/spooler
49:local7.*                                                /var/log/boot.log

# 第二种实现：直接匹配行首非 # 开头的
# 因为使用了中括号表示需要有一个字符存在，所以空行的不会被匹配
[mrcode@study tmp]$ grep -n '^[^#]' /etc/rsyslog.conf 
9:$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)
10:$ModLoad imjournal # provides access to the systemd journal
26:$WorkDirectory /var/lib/rsyslog
29:$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat
36:$IncludeConfig /etc/rsyslog.d/*.conf
40:$OmitLocalLogging on
43:$IMJournalStateFile imjournal.state
54:*.info;mail.none;authpriv.none;cron.none                /var/log/messages
57:authpriv.*                                              /var/log/secure
60:mail.*                                                  -/var/log/maillog
64:cron.*                                                  /var/log/cron
67:*.emerg                                                 :omusrmsg:*
70:uucp,news.crit                                          /var/log/spooler
73:local7.*                                                /var/log/boot.log

```

这里要注意的是批注可以出现在任意处，所以匹配行首的是最安全的做法

### 范例 4：任意一个字符 `.` 与重复字符 `*`

在第十章 bash 中，通配符 `*`表示任意（0 或 多个）字符，但是正则表达式中并不是这样，他们含义如下：

- `.`：一定有一个任意字符
- `*`：重复前一个字符，0  到任意次，为组合形态

```bash
# 找出 g??d 的字符串，也就是 g 开头 d 结尾的 4 字符的字符串
[mrcode@study tmp]$ grep -n 'g..d' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
9:Oh! The soup taste good.
16:The world <Happy> is the same with "glad".

# 找出 oo、ooo、ooo 等数据，至少含有 2 个 o
# 注意，这里不能写 oo* 因为，*是作用于第二个 o 的，表示 0 到任意个
# 也就是说如果是 oo* 有可能匹配到一个 o 
[mrcode@study tmp]$ grep -n 'ooo*' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
9:Oh! The soup taste good.
18:google is the best tools for search keyword.
19:goooooogle yes!

# 找出 开头与结尾都是 g ，并且中间至少含有一个 o 的数据
# 也就是 gog、goog 之类的数据
[mrcode@study tmp]$ grep -n 'goo*g' regular_express.txt 
18:google is the best tools for search keyword.
19:goooooogle yes!

# 找出 开头与结尾都是 g，中间有无字符均可
[mrcode@study tmp]$ grep -n 'g*g' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
3:Football game is not use feet only.
9:Oh! The soup taste good.
13:Oh!  My god!
14:The gd software is a library for drafting programs.
16:The world <Happy> is the same with "glad".
17:I like dog.
18:google is the best tools for search keyword.
19:goooooogle yes!
20:go! go! Let's go.
# 使用 g*g 发现第一行的数据就不匹配，这个还是需要再终端看，因为可以开启高亮，方便查看哈
# 原因是 * 作用于 g，g* 代表空字符或一个以上的 g，因此应该匹配 g、gg、ggg 等

# 正确的应该这样实现
[mrcode@study tmp]$ grep -n 'g.*g' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
14:The gd software is a library for drafting programs.
18:google is the best tools for search keyword.
19:goooooogle yes!
20:go! go! Let's go.

# 找出包含任意数字的数据
# 同上，[0-9]* 只作用于一个中括号
[mrcode@study tmp]$ grep -n '[0-9][0-9]*' regular_express.txt 
5:However, this dress is about $ 3183 dollars.
15:You are the best is mean you are the no. 1.
# 直接使用 grep -n '[0-9]' regular_express.txt 也可以得到相同结果哈
```

### 范例 5：限定连续 正则字符范围 `{}`

找出 2 个到 5 个 o 的连续字符串

```bash
# 华括弧在 shell 中是特殊符号，需要转义
[mrcode@study tmp]$ grep -n 'o\{2\}' regular_express.txt 
1:"Open Source" is a good mechanism to develop programs.
2:apple is my favorite food.
3:Football game is not use feet only.
9:Oh! The soup taste good.
18:google is the best tools for search keyword.
19:goooooogle yes!
# 上述结果是至少是 2 个 oo 的出来了

# 单词开头结尾都是 g，中间 o，至少 2 个，最多 5 个
[mrcode@study tmp]$ grep -n 'go\{2,5\}g' regular_express.txt 
18:google is the best tools for search keyword.

# 承上，只是中间的 o 至少 2 个
[mrcode@study tmp]$ grep -n 'go\{2,\}g' regular_express.txt 
18:google is the best tools for search keyword.
19:goooooogle yes!

```

## 基础正则表示法字符汇总

- `^word`：搜索的关键词 word 在行首

  范例：搜索行首为 # 的，并列出行号 `grep -n '^#' file`

- `word$`：搜索的关键词 word 在行尾

  范例：搜索以 ！结尾的，`grep -n '!$' file` 

- `.`：一定有一个任意字符

  范例：搜索字符串可以是 eve、eae、eee、e e；`grep -n 'e.e' file`

- `\`：转义字符

  范例：搜索含有单引号数据。`grep -n '\’' file`

- `*`：重复另个到无穷多个前一个字符

  范例：找出含有 es、ess、esss 等字符串；`grep -n 'es*' file`

- `[list]`：里面列出想要截取的字符合集

  范例：找出含有 g1 或 gd 的数据；`grep -n 'g[1d]' file`

- `[n1-n2]`：字符合集范围

  范例：找出含有任意大写字母的数据；`grep -n '[A-Z]' file`

- `[^list]`：不要包含该集合中的字符或该范围的字符

  范例：找出 ooa、oog 但是不包含 oot 的数据; `grep -n 'oo[^t]'`

- `\{n,m\}`：连续 n 到 m 个前一个字符

- `\{n\}`：连续 n 个前一个字符

- `\{n,\}`：至少 n 个以上的前一个字符；咋效果上感觉和 `\{n\}` 是一样的

最后再强调，通配符和正则表达式不一样，比如在 ls 命令中找出以 a 开头的文件

- 通配符：`ls -l a*`
- 正则表达式：`ls | grep -n '^a'` 或则 `ls | grep -n '^a.*'` 

```bash
# 范例：以 ls -l 配合 grep 找出 /etc/ 下文件类型为链接文件属性的文件名
# 符号链接文件的特点是权限前面一位是 l，根据 ls 的输出，只要找到行首为 l 的即可
[mrcode@study tmp]$ ls -l /etc | grep '^l'
lrwxrwxrwx.  1 root root       56 Oct  4 18:22 favicon.png -> /usr/share/icons/hicolor/16x16/apps/fedora-logo-icon.png
lrwxrwxrwx.  1 root root       22 Oct  4 18:23 grub2.cfg -> ../boot/grub2/grub.cfg

```

## sed 工具

了解了一些正则基础使用后，可以来玩一玩 sed 和 awk ；作者就利用他们两个实现了一个小工具：logfile.sh 分析登录文件（第十八章会讲解）。里面绝大部分关键词的提取、统计等都是通过他们来完成的

sed：本身是一个管线命令，可以分析 standard input 的数据，还可以将数据进行替换、新增、截取特定行等功能

```bash
sed [-nefr] [动作]
```

选项与参数：

- n：使用安静（silent）模式

  在一般 sed 的用法中，所有来自 STDIN 的数据一般都会列出到屏幕上，加上 -n 之后，只有经过 sed 特殊处理的那一行（或则动作）才会被打印出来

- e：直接在指令模式上进行 sed 的动作编辑

- f：直接将 sed 的动作写在一个文件内，- f filename 则可以执行 filename 内的 sed 动作

- r：sed 的动作支持是延伸类型正则表达式的语法（预设是基础正则表达式语法）

- i：直接修改读取的文件内容，而不是由屏幕输出

动作说明：`[n1[,n2]]function`

`n1,n2`：不见得会存在，一般代表「选择进行动作的行数」，比如：如果我的动作是需要再 10 到 20 行之间进行的，则「10,20[动作行为]」

function 有如下：

- a：新增，a 后面可以接字符串，这些字符串会在新的一行出现（当前的下一行）
- c：替换，c 后面可以接字符串，这些字符串替换 n1,n2 之间的行
- d：删除，后面不接任何字符串
- i：插入，i 的后面可以接字符串，而这些字符串会在新的一行出现（当前的上一行）
- p：打印，将某个选择的数据打印。通常 p 会参与 sed -n 一起运作
- s：替换，可以直接进行替换工作。通常这个 s 的动作可以搭配正则表达式，例如：`1,20s/old/new/g`


### 以行为单位的新增/删除功能

```bash
# 范例1：将 /etc/passwd 的内容列出并且打印行号，同时将第 2~5 行删除
[mrcode@study ~]$ nl /etc/passwd | sed '2,5d'   	# 注意写法和结果
     1  root:x:0:0:root:/root:/bin/bash
     6  sync:x:5:0:sync:/sbin:/bin/sync
     7  shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
# 另外这里，应该带上 sed -e '2,5d' 才标准，不过不带也可以，但是需要使用单引号括起来
# 实测不用单引号也可以实现

# 范例2：只删除第二行
[mrcode@study ~]$ nl /etc/passwd | sed '2d'

# 范例3：删除第三行到最后一行
[mrcode@study ~]$ nl /etc/passwd | sed '3,$d'
     1  root:x:0:0:root:/root:/bin/bash
     2  bin:x:1:1:bin:/bin:/sbin/nologin

# 范例4：在第二行后（也就是加载第三行）加上「drink tea？」字样
[mrcode@study ~]$ nl /etc/passwd | sed '2a drink tea?'
     1  root:x:0:0:root:/root:/bin/bash
     2  bin:x:1:1:bin:/bin:/sbin/nologin
drink tea?
     3  daemon:x:2:2:daemon:/sbin:/sbin/nologin

# 范例5：在第二行后面加入两行字
# 注意：不要一开始就写好所有的单引号，因为需要使用 \ + 回车触发换行
[mrcode@study ~]$ nl /etc/passwd | sed '2a drink tea \
> drink beer?'
     1  root:x:0:0:root:/root:/bin/bash
     2  bin:x:1:1:bin:/bin:/sbin/nologin
drink tea 
drink beer?

```

### 以行为单位的取代显示功能

```bash
# 范例1：将第 2-5 行的内容替换为 no 2-5 nuber
[mrcode@study ~]$ nl /etc/passwd | sed '2,5c no 2-5 number'
     1  root:x:0:0:root:/root:/bin/bash
no 2-5 number

# 范例2：取出第 11-20 行
# 通过之前的知识来达成需要这样写
[mrcode@study ~]$ nl /etc/passwd | head -n 20 | tail -n 10
    11  games:x:12:100:games:/usr/games:/sbin/nologin
    12  ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
    13  nobody:x:99:99:Nobody:/:/sbin/nologin
    14  systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
    15  dbus:x:81:81:System message bus:/:/sbin/nologin
    16  polkitd:x:999:998:User for polkitd:/:/sbin/nologin
    17  colord:x:998:997:User for colord:/var/lib/colord:/sbin/nologin
    18  libstoragemgmt:x:997:995:daemon account for libstoragemgmt:/var/run/lsm:/sbin/nologin
    19  rpc:x:32:32:Rpcbind Daemon:/var/lib/rpcbind:/sbin/nologin
    20  saslauth:x:996:76:Saslauthd user:/run/saslauthd:/sbin/nologin
# 注意需要使用 -n 只输出 sed 处理过的数据
[mrcode@study ~]$ nl /etc/passwd | sed -n '11,20p'

```

### 部分数据的搜索并替换功能

除了整行的处理模式外，还可以用行为单位进行部分数据的搜索并替换的功能，基本上 sed 的搜索与替换与 vi 类似

```bash
sed 's/要被替换的字符串/新的字符串/g'
```

```bash
# 范例1：先观察原始信息，利用 /sbin/ifconfig 查询 IP
[mrcode@study ~]$ /sbin/ifconfig 
enp0s3: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 192.168.0.128  netmask 255.255.255.0  broadcast 192.168.0.255
        inet6 fe80::deb9:3a1b:fd0f:f6c2  prefixlen 64  scopeid 0x20<link>
        ether 08:00:27:a0:49:8f  txqueuelen 1000  (Ethernet)
        RX packets 2436261  bytes 219827411 (209.6 MiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 2011081  bytes 319310584 (304.5 MiB)
# 还未讲解到 IP,这里先关注第二行的 IP

# 利用关键词配合 grep 截取出关键的一行数据
[mrcode@study ~]$ /sbin/ifconfig enp0s3 | grep 'inet '
        inet 192.168.0.128  netmask 255.255.255.0  broadcast 192.168.0.255

# 将 ip 前面的信息删除，也就是 inet 
[mrcode@study ~]$ /sbin/ifconfig enp0s3 | grep 'inet ' | sed 's/inet //g'
        192.168.0.128  netmask 255.255.255.0  broadcast 192.168.0.255
# 需要使用通配符，不然会留下前面的空白符号：任意字符开头另个或多个
[mrcode@study ~]$ /sbin/ifconfig enp0s3 | grep 'inet ' | sed 's/^.*inet //g'
192.168.0.128  netmask 255.255.255.0  broadcast 192.168.0.255

# 再删除后续部分，只剩下 192.168.0.128
# 注意这里需要使用：空格任意个，来匹配前面多个空格
[mrcode@study ~]$ /sbin/ifconfig enp0s3 | grep 'inet ' | sed 's/^.*inet //g' | sed 's/ *netmask.*$//g'
192.168.0.128

```

上面例子建议一步一步的来做，下面继续研究 sed 与正则表示法配合练习

```bash
# 范例2：只要 MAN 存在的那几行数据，但是含有 # 在内的批注和空白行不要
# 步骤1：先使用 grep 将关键词 MAN 所在行取出来
[mrcode@study ~]$ cat /etc/man_db.conf | grep 'MAN'
# MANDATORY_MANPATH                     manpath_element
# MANPATH_MAP           path_element    manpath_element
# MANDB_MAP             global_manpath  [relative_catpath]
# every automatically generated MANPATH includes these fields
#MANDATORY_MANPATH                      /usr/src/pvm3/man
MANDATORY_MANPATH                       /usr/man
MANDATORY_MANPATH                       /usr/share/man
...省略...
# 步骤2：删除掉批注数据行
[mrcode@study ~]$ cat /etc/man_db.conf | grep 'MAN' | sed 's/^#.*$//g'





MANDATORY_MANPATH                       /usr/man
MANDATORY_MANPATH                       /usr/share/man
MANDATORY_MANPATH                       /usr/local/share/man
# 步骤3：删除空白行
# 注意这里使用了动作里面的 d 命令，前面是正则匹配？
[mrcode@study ~]$ cat /etc/man_db.conf | grep 'MAN' | sed 's/^#.*$//g' | sed '/^$/d'
MANDATORY_MANPATH                       /usr/man
MANDATORY_MANPATH                       /usr/share/man
MANDATORY_MANPATH                       /usr/local/share/man

```

### 直接修改文件内容（危险动作）

``` bash
# 范例1：利用 sed 将 /tmp/regular_express.txt 内每一行结尾若为 . 则换成 ！
# 下面还是使用了动作 s 替换，后面的是转义 . 和 !
# 这样可以直接修改文件内容
[mrcode@study tmp]$ sed -i 's/\./\!/g' regular_express.txt 

# 范例2：利用 sed 直接在 /tmp/regular_express.txt 最后一行加入 # This is a test
# $ 表示最后一行
[mrcode@study tmp]$ sed -i '$a # This is a test ' regular_express.txt 
# 想要删除最后一行就简单了
[mrcode@study tmp]$ sed -i '$d' regular_express.txt 
```

## 延伸正则表示法

一般来说，只要了解了基础正则表示法大概就已经相当足够了，所谓技多不压身；还可以了解使用范围更广的延伸正则表示法。举个例子：前面讲解到要去除空白行与行首为 `#` 的行，使用的是

```bash
grep -v '^$' regular_express.txt | grep -v '^#'
```

需要使用到管线命令来搜寻两次，使用延伸的正则表示法则如下

```bash
egrep -v '^$|^#' regular_express.txt
```

此外，grep 预设仅支持基础的正则表示法，可以使用 `-E` 参数开启，不过建议用别名 egrep

下面是延伸正则表示法的符号（RE 字符）说明：

- `+`：重复「一个或一个以上」的前一个 RE 字符

  范例：搜索 (god)(good)(goood)...等字符串。 可以使用 

  ```bash
  [mrcode@study tmp]$ egrep -n 'go+d' regular_express.txt 
  1:"Open Source" is a good mechanism to develop programs!
  9:Oh! The soup taste good!
  13:Oh!  My god!
  ```

- `?`：「0 个或 1 个」的前一个 RE 字符

  范例：搜索 gd、god 

  ```bash
  [mrcode@study tmp]$ egrep -n 'go?d' regular_express.txt 
  13:Oh!  My god!
  14:The gd software is a library for drafting programs!
  ```

- `|`：用或（or）的方式找出数个字符串

  范例：搜索 gd 或 good 

  ```bash
  [mrcode@study tmp]$ egrep -n 'gd|good' regular_express.txt 
  1:"Open Source" is a good mechanism to develop programs!
  9:Oh! The soup taste good!
  14:The gd software is a library for drafting programs!
  ```

- `()`：找出「群组」字符串

  范例：搜索 glad 或 good 

  ```bash
  # 当然，这里使用上面完整的或来匹配两个固定单词也是可以的
  [mrcode@study tmp]$ egrep -n 'g(la)|(oo)d' regular_express.txt 
  1:"Open Source" is a good mechanism to develop programs!
  2:apple is my favorite food!
  9:Oh! The soup taste good!
  16:The world <Happy> is the same with "glad"!
  ```

- `()+`：多个重复群组的判别

  范例：将「AxyzxyzxyzxyzC」用 echo 叫出，然后再使用如下的方法搜索

  ```bash
  [mrcode@study tmp]$ echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)'
  Axyz xyzxyzxyzC # 在命令行中是有红色高亮的，这个只能高亮到 Axyz
  [mrcode@study tmp]$ echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)+'
  Axyzxyzxyzxyz C # C 不会高亮
  [mrcode@study tmp]$ echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)+C'
  AxyzxyzxyzxyzC # 完全匹配
  ```

::: tip
要特别注意：`grep -n '[!>]' xx.txt` 的含义并不是除了 > 字符之外的字符，因为 `!`  不是一个特殊符号

想要表示非，需要这样写 `grep -n '[^a-z]' xx.txt`

:::

##  文件的格式化与相关处理

不需要通过 vim 去编辑，而是通过数据流重导向配置 printf 功能以及 awk 指令，可以对文字信息进行排版显示

## 格式化打印：printf

比如将考试分数输出，姓名与科目及分数之间，稍微做个比较漂亮的版面，比如输出下面这样的表格

```
Name		Chinese		Enlish		Math		Average
DmTsai		80				60				92			77.33
VBird			75				55				80			70.00
Ken				60				90				70			73.33
```

上表数据主要分成 5 个字段，每个字段之间可以使用 tab 或空格进行分割。将上表存储到 printf.txt 文件中，后续会使用到这个文件进行练习。

由于每个字段的长度并不一样，所以要达到上表效果，就需要打印格式管理员 printf 来帮忙了

```bash
printf '打印格式' 实际类容
选项与参数：
 关于格式方面的几个特殊样式：
 		\a	警告剩余输出
 		\b	退格键（backspace）
 		\f	清楚屏幕（form feed）
 		\n 	输出新的一行
 		\r	Enter 按键，换行
 		\t	水平的 tab 按键
 		\v	垂直的 tab 按键
 		\xNN	NN 为两位数的数字，可以转换数字称为字符
 关于 C 程序语言内，常见的变量格式：
 		%ns		n 数字，s 表示 string，也就是多少个字符
 		%ni		n 数字，i 表示 integer，多少整数数字
 		%N.nf 	n 与 N 都是数字，f 表示 floating（浮点），如果有小数，比如共 10 个位数，小数点 2 位数，则写成 %10.2f
```

下面进行练习

```bash
# 范例 1：将上面存储的 printf.txt 内容仅列出姓名与成绩，并且用 tab 分割
# 文件存储时，字段之间全部用 tab 隔开的，复制进去就变成下面展示这样了
 [mrcode@study tmp]$ cat printf.txt 
Name            Chinese         Enlish          Math            Average
DmTsai          80                              60                              92                      77.33
VBird                   75                              55                              80                      70.00
Ken                             60                              90                              70                      73.33
# 由于 printf 不是管线命令，需要通过 cat 先提取出来内容
# %s 表示不固定长度的字符串，后面跟了一个空格，并使用横向制表符 \t 来格式化
[mrcode@study tmp]$ printf '%s \t %s \t %s \t %s \t %s \t \n ' $(cat printf.txt)
Name     Chinese         Enlish          Math    Average         
 DmTsai          80      60      92      77.33   
 VBird   75      55      80      70.00   
 Ken     60      90      70      73.33 
```

可以看到上述的效果虽然好多了，但是还是没有对齐。可能是由于 Chinese 比其他的长度要长，导致对不齐，那么下面来固定长度

```bash
# 范例 2：将上述第二行以后，分别以字符串、整数、小数点来显示
# grep -v Name 排除包含 Name 字符的行
[mrcode@study tmp]$ printf '%10s %5i %5i %5i %8.2f \n' $(cat printf.txt | grep -v Name)
    DmTsai    80    60    92    77.33 
     VBird    75    55    80    70.00 
       Ken    60    90    70    73.33 
# 由于这里是格式化数字，所以第一行无法使用这里的表达式，如果使用将得到数字 0 的展示
# 展示效果好了很多
 %10s：这一个字段永远显示 10 个字符宽度，不足的用空格补位
 %8.2f：表示 00000.00
```

printf 除了可以格式化处理之外，还可以根据 ASCII 的数字与图形对应来显示数据，如下

```bash
# 范例 3： 列出 16 进制 45 代表的字符是什么
[mrcode@study tmp]$ printf '\x45\n'
E
# 可以将数值转换为字符，如果你会写 script 的话
# 可以测试下，20~80 之间的数值表示的字符是什么
```

printf 使用相当广泛，包括后面提到的 awk 以及在 c 程序语言中使用的屏幕输出，都是利用 printf。

printf 使用场景就是格式化输出，如果你要写自己的软件，把信息漂亮的输出到屏幕的话，可是很有用的

## awk：好用的数据处理工具

- sed：常常用于一整行的处理
- awk：倾向于将一行分成数个字段来处理

因此，awk 适合处理小型的数据处理。

```bash
awk '条件类型1{动作1} 条件类型2{动作2} ...' filename

awk 后可以跟文件，也可以接受前个指令的 standard output
awk 主要处理每一行的字段内的数据，他默认的分隔符为「空格键」或「tab 键」
```

```bash
# 范例：使用 last 将登录者数据取出来
[mrcode@study tmp]$ last -n 5		# 取出前 5 行
mrcode   pts/1        192.168.0.105    Wed Jan 15 22:20   still logged in   
mrcode   pts/0        192.168.0.105    Wed Jan 15 22:20   still logged in   
reboot   system boot  3.10.0-1062.el7. Wed Jan 15 22:19 - 23:05  (00:45)    
mrcode   pts/1        192.168.0.105    Mon Jan 13 22:51 - 23:13  (00:22)    
mrcode   pts/0        192.168.0.105    Mon Jan 13 22:51 - 23:13  (00:22) 

# 若要取出账户与登录 IP ，且账户与 IP 之间以 tab 隔开，可以这样写
[mrcode@study tmp]$ last -n 5 | awk '{print $1 "\t" $3}'
mrcode  192.168.0.105
mrcode  192.168.0.105
reboot  boot
mrcode  192.168.0.105
mrcode  192.168.0.105
        
wtmp    Fri
# 由于每一行数据都需要处理，所以不需要有条件类型
# 通过 print 功能将数据列出来
# 第 3 行数据被误判了，第二个字段中包含了空格
# 那么 $1 开始的变量表示哪一个字段，要注意的是：$0 表示整行数据
```

对于上面示例，awk 的处理流程是：

1. 读入第一行，并将第一行的内容填入 `$0、$1...` 变量中
2. 依据 条件类型 的限制，判断是否需要进行后面的 动作
3. 做完所有的动作与条件类型
4. 若还有后续的「行」数据，则重复上面 1~3 步骤，直到所有数据都处理完为止

awk 是「以行为一次处理的单位」而「以字段为最小的处理单位」，那么 awk 中还提供了以下变量信息

| 变量名称 |               含义                |
| :------: | :-------------------------------: |
|    NF    |   每一行（`$0`）拥有的字段总数    |
|    NR    | 目前 awk 所处理的是「第几行」数据 |
|    FS    |    目前的分割字符，默认是空格     |

继续上面 last -n 5 的例子来做说明

```bash
# 想要列出每一行的账户：就是 $1
# 列出目前处理的行数：NR 变量
# 该行有多少字段：NF 变量
# 注意：在 awk 的格式内使用 print 打印时，非变量部分需要用双引号引用起来，因为 awk 动作是以单引号的
[mrcode@study ~]$ last -n 5 | awk '{print $1 "\t lines:" NR "\t columns:" NF}'
mrcode   lines:1         columns:10
mrcode   lines:2         columns:10
reboot   lines:3         columns:11
mrcode   lines:4         columns:10
mrcode   lines:5         columns:10
         lines:6         columns:0
wtmp     lines:7         columns:7
# 注意 NF 等变量不需要有 $ 并且需要大写
```

### awk 的逻辑运算字符

既然有「条件」，那么就有逻辑运算符号

| 运算单元 |  代表意义  |
| :------: | :--------: |
|   `>`    |    大于    |
|   `<`    |    小于    |
|   `>=`   | 大于或等于 |
|   `>=`   | 小于或等于 |
|   `==`   |  **等于**  |
|   `!=`   |   不等于   |

范例：在 /etc/passwd 中是以冒号「:」来分割字段的，第一个字段为账户，第三字段则是 UID.

```bash
# 查阅 第三栏小于 10 以下的数据，并且仅列出账户与第三栏
# FS 是字段分隔符
[mrcode@study ~]$ cat /etc/passwd | awk '{FS=":"} $3 < 10 {print $1 "\t" $3}'
root:x:0:0:root:/root:/bin/bash 
bin     1
daemon  2
adm     3
lp      4
sync    5
shutdown        6
halt    7
mail    8
```

第一行，没有生效是为啥呢？在 awk 中，在上述定义中，FS 仅能在第二行开始，

```bash
# 需要使用关键字 BEGIN，对应的还有 END
[mrcode@study ~]$ cat /etc/passwd | awk 'BEGIN {FS=":"} $3 < 10 {print $1 "\t" $3}'
root    0
bin     1
daemon  2
```

使用 awk 的计算功能，比如有如下的数据 pay.txt

```
Name		1st		2nd		3th
Mrcode	2300	2400	2500
DMTsai	2100	2000	2300
Mrcode2	4300	4200	4100
```

```bash
# 计算每个人的总额，而且还要格式化输出
 - 第一行是说明，不需要计算，所以需要使用条件 NR=1 时再处理
 - 第二行才开始计算，NR >=2 才处理

[mrcode@study tmp]$ cat pay.txt | 
> awk 'NR==1 {printf "%10s %10s %10s %10s %10s\n",$1,$2,$3,$4,"Total" }
> NR>=2 {total = $2 + $3 + $4 ; printf "%10s %10d %10d %10d %10.2f\n",$1,$2,$3,$4,total}'
      Name        1st        2nd        3th      Total
    Mrcode       2300       2400       2500    7200.00
    DMTsai       2100       2000       2300    6400.00
   Mrcode2       4300       4200       4100   12600.00

为了方便复制，这里粘贴上完整的一行命令：cat pay.txt |  awk 'NR==1 {printf "%10s %10s %10s %10s %10s\n",$1,$2,$3,$4,"Total" } NR>=2 {total = $2 + $3 + $4 ; printf "%10s %10d %10d %10d %10.2f\n",$1,$2,$3,$4,total}'

# 现在来分解上面指令
# 1. 在 awk 中，非变量需要使用双引号引用起来
# 2. 使用 printf 时，需要加上 \n 才能换行
# 下面的含义是，当是第一行的时候，执行打印个格式化，前面是格式化表达式
# 后面用逗号分割，给出对应内容，这里给出了 1~4 个字段，并新增了一个 total 字段
[mrcode@study tmp]$ cat pay.txt | awk 'NR==1 {printf "%10s %10s %10s %10s %10s\n",$1,$2,$3,$4,"total"}'
      Name        1st        2nd        3th      total

# 对于计算的讲解
# 1. 在{} 动作中可以设置变量，进行运算；这里设置了一个 total 变量，并把 1~3 个字段相加
# 2. 由于这里有多个指令，所以需要使用冒号 「;」 进行分割
# 3. 使用 printf 常规打印，第 5 个字段引用了动作内设置的变量 total，记住 awk 中引用变量不需要使用 % 符号
[mrcode@study tmp]$ cat pay.txt | awk 'NR>=2 {total=$1+$2+$3 ; printf "%10s %10d %10d %10d %10.2f\n",$1,$2,$3,$4,total}'
    Mrcode       2300       2400       2500    4700.00
    DMTsai       2100       2000       2300    4100.00
   Mrcode2       4300       4200       4100    8500.00

# 那么上面两条是针对各自条件进行处理的，相当于 if 语句；多个条件动作之间使用空格分割；链接起来就完成了
```

利用 awk 可以帮助我们处理很多日常工作了，在 awk 的输出格式中，常常会以 printf 来辅助。另外在 {} 动作内，也支持 if(条件) 语句。那么上面的指令可以使用 if 来做，如下

```bash
cat pay.txt | awk '{if(NR==1) printf "%10s %10s %10s %10s %10s\n",$1,$2,$3,$4,"Total" } NR>=2 {total = $2 + $3 + $4 ; printf "%10s %10d %10d %10d %10.2f\n",$1,$2,$3,$4,total}'
```

笔者没有感觉这个 if 有多方便啊？

另外，awk 还可以进行循环计算，不过这个属于比较进阶的单独课程了

## 文件比对工具

通常会在同一个软件包的不同版本之间，比较配置文件与原始文件的差异的时候，就会用到文件对比。

很多时候所谓的对比，通常是用在 ASCII 纯文本的比对。常见的指令有 diff，还可以使用 cmp 来对比非纯文本。同时也可以使用 diff 建立分析文档，以处理补丁 patch 功能的文件

### diff

diff 用在比对两个文件之间的差异，以行为单位来比对的。一般是用在 ASCII 纯文本文件的比对上。

比如：将 /etc/passwd 删除第 4 行，第 6 行则替换为「no six line」，新文件放置到 /tmp/test 里，该如何做？

```bash
# 创建测试目录
[mrcode@study tmp]$ mkdir -p /tmp/testpw
[mrcode@study tmp]$ cd /tmp/testpw/
[mrcode@study testpw]$ cp /etc/passwd passwd.old 
# sed -e 直接在命令行模式上修改；d 是删除，c是替换；前面 sed 中有讲到过的
# 这里把修改后的内容存到了 passwd.new 文件中
# sed 中有超过两个以上的动作时需要加 -e
[mrcode@study testpw]$ cat /etc/passwd | sed -e '4d' -e '6c no six line' > passwd.new

```

```bash
diff [-bBi] from-file to-file
选项与参数：

from-file：文件名，原始对比文件
to-file：文件名，目的比较文件
注意：两个文件，都可以使用 - 表示，- 代表 standard input

-b：忽略一行当中，仅有多个空白的差异；例如：“about me“ 与 “about         me” 视为相同
-B：忽略空白行的差异
-i：忽略大小写的不同
```

```bash
# 范例 1：比对 passwd.old passwd.new 文件
[mrcode@study testpw]$ diff passwd.old passwd.new 
4d3						# 左边第 4 行被删除(d)掉了，基准是右边第 3 行
< adm:x:3:4:adm:/var/adm:/sbin/nologin				# 列出了左边被删除的那一行内容
6c5						# 左边第 6 行，被替换（c）成右边文件的第 5 行
< sync:x:5:0:sync:/sbin:/bin/sync			# 左边文件第 6 行内容
---	
> no six line								# 右边文件第 5 行内容
# 注意这里的，左边第 4 行被删除意思是：左边文件是完整的，右边是修改之后的，右边与左边对比，原来的第 4 行被删除了
```

如果用 diff 去对比两个完全不相干的文件，是对比不出来什么的；另外 diff 还可以对比整个目录下的差异

```bash
# 范例：了解一下不同的开机执行等级（runlevel）内容有啥不同？假设你已经知道执行等级 0 与 5的启动脚本分别放置到 /etc/rc0.d 及 /etc/rc5.d 则可以对比下
[mrcode@study testpw]$ diff /etc/rc0.d/ /etc/rc5.d/
只在 /etc/rc0.d/ 存在：K90network
只在 /etc/rc5.d/ 存在：S10network
```

### cmp

cmp 主要也是对比两个文件，主要利用字节单位去对比

```bash
cmp [-l] file1 file2
-i：将所有的不同点的字节处都列出来。因为 cmp 预设仅会输出第一个发现的不同点
```

```bash
# 范例 1：用 cmp 比较 passwd.old 与 passwd.new
[mrcode@study testpw]$ cmp passwd.old passwd.new 
passwd.old passwd.new 不同：第 106 字节，第 4 行
```

### patch

patch 与 diff 可配合使用，diff 比较出不同，而 patch 则可以将「旧文件升级为新的文件」。

1. 先比较新旧版本的差异
2. 将差异制作成补丁文件
3. 再由补丁文件更新旧文件

```bash
# 范例 1：以 /tmp/testpw 内的 passwd.old 与 passwd.new 制作补丁文件
[mrcode@study testpw]$ diff -Naur passwd.old passwd.new > passwd.patch
[mrcode@study testpw]$ cat passwd.patch 
--- passwd.old	2020-01-17 15:58:55.405462402 +0800			# 新旧文件的信息
+++ passwd.new	2020-01-17 16:01:03.115462402 +0800
@@ -1,9 +1,8 @@		# 新旧文件要修改数据的界定范围，旧文件在 1-0 行，新文件在 1-8 行
 root:x:0:0:root:/root:/bin/bash
 bin:x:1:1:bin:/bin:/sbin/nologin
 daemon:x:2:2:daemon:/sbin:/sbin/nologin
-adm:x:3:4:adm:/var/adm:/sbin/nologin			# 左侧文件删除
 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
-sync:x:5:0:sync:/sbin:/bin/sync				# 左侧文件删除
+no six line									# 右侧新加入
 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
 halt:x:7:0:halt:/sbin:/sbin/halt
 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
 
 # 这里怎么理解？ 可以理解为 old 文件是基准文件
 # 根据这里的基准文件，看到 - 就剪掉，看到 + 就增加；执行完成后，则会得到 new 这个文件；
 # 并且补丁中限制了行数。
```

将 passwd.old 同步为 passwd.new 相同的内容，

```bash
# 由于系统未预装 patch 软件，需要将之前的 iso 镜像文件挂载
# 在虚拟机上找到顺序为 0 的控制器位置，选择 iso 文件，设备就能被 linux 找到了
[root@study ~]# mount /dev/sr0 /mnt/
mount: /dev/sr0 写保护，将以只读方式挂载
[root@study ~]# rpm -ivh /mnt/Packages/patch-2.*
警告：/mnt/Packages/patch-2.7.1-11.el7.x86_64.rpm: 头V3 RSA/SHA256 Signature, 密钥 ID f4a80eb5: NOKEY
准备中...                          ################################# [100%]
正在升级/安装...
   1:patch-2.7.1-11.el7               ################################# [100%]
[root@study ~]# umount /mnt/
[root@study ~]# exit
# 透过上述方式安装所需软件
```

语法

```bash
patch -pN < patch_file  # 更新
patch -R -pN < patch_file  # 还原

选项与参数：
-p：后面可以接 取消几层目录 的意思
-R：代表还原，将新的文件还原成原来的旧文件
```

```bash
# 范例 2：将刚刚制作出来的 patch file 用来更新旧版本数据
[mrcode@study testpw]$ patch -p0 < passwd.patch 
patching file passwd.old
[mrcode@study testpw]$ ll passwd.*
-rw-rw-r--. 1 mrcode mrcode 2266 1月  17 16:01 passwd.new
-rw-r--r--. 1 mrcode mrcode 2266 1月  17 16:50 passwd.old	# 文件大小和new文件一样了
-rw-rw-r--. 1 mrcode mrcode  480 1月  17 16:38 passwd.patch

# 范例 3：恢复旧文件内容
[mrcode@study testpw]$ patch -R -p0 < passwd.patch 
patching file passwd.old
[mrcode@study testpw]$ ll passwd.*
-rw-rw-r--. 1 mrcode mrcode 2266 1月  17 16:01 passwd.new
-rw-r--r--. 1 mrcode mrcode 2323 1月  17 16:52 passwd.old
```

这里为什么会使用 `-p0` ？因为两个文件在同一个目录下，因此不需要减去目录。如果是整体目录比对（diff 旧目录 新目录）时，就要依据建立 patch 文件所在目录来进行目录删减

更详细的 patch 用法在后续的第二十章「原始码编译」

### 文件打印准备：pr

在图形界面中的文字处理软件，打印时可以选择每一页的标头和页码，在文字界面下，可以使用 pr 来实现，由于 pr 参数实在太多了，这里使用最简单的方式来处理

```bash
# 打印 /etc/man_db.conf
[mrcode@study testpw]$ pr /etc/man_db.conf 


2018-10-31 04:26                /etc/man_db.conf                 第 1 页


# 
#
# This file is used by the man-db package to configure the man and cat paths.
# It is also used to provide a manpath for those without one by examining
# their PATH environment variable. For details see the manpath(5) man page.
```

最上面的一行就是 pr 处理之后的效果。依次是：文件时间、文件名、页码


## 重点回顾

- 正则表示法就是处理字符串的方法，他是以行尾单位进行字符串的处理行为
- 正则表示法通过一些特殊符号的辅助，可以让使用者轻易的达到搜索、删除、替换某特定字符串的处理程序
- 只要工具程序支持正则表示法，那么该工具程序就可以用来作为正则表示法的字符串处理
- 正则表示法与通配符是完全不一样的概念。通配符代表的是 bash 操作接口的一个功能，但正则表示法则是一种字符串处理的表示方法
- 使用 grep 或其他工具进行正则表示法的字符串比对时，因为编码的问题会有不同的状态，因此最好将 LANG 等变量设置为 C 或者是 en 等英文语系
- grep 与 egrep 在正则表示法是很常见的程序，其中 egrep 支持更严谨的正则表示法
- 由于编码系统的不同，不同的语系（LANG）会造成正则表示法截取的差异。因此可以利用特殊符号如`[:upper:]` 来替代编码范围较佳
- 由于严谨度的不同，正则表示法之上还有更严谨的延伸正则表示法
- 基础正则表示法的特殊字符有：`*,.,[],[-],[^],^,$`等
- 常见的支持正则表示法的工具软件有：grep、sed、vim 等
- printf 可以通过一些特殊符号来将数据进行格式化输出
- awk 可以使用「字段」为依据，进行数据的重新整理与输出
- 文件的比对中，可利用 diff 以及 cmp 进行比对，其中 diff 主要用在纯文本文件方面的新旧版本比较
- patch 指令可以将旧版本数据更新到新版本（主要由 diff 建立 patch 的补丁来源文件）


## 本章练习

## 情景题 1

情景模拟题：通过 grep 搜索特殊字符串，并配合数据流重导向来处理大量的文件搜索问题

- 目标：正确使用正则表示法
- 前提：需要了解数据流重导向，以及通过子指令 `${command}` 来处理文件名的搜索

搜索 * 号来处理下面的任务

1. 利用正则表示法找出系统中含有某些特殊关键词的文件

   找出 /etc 下含有星号的文件与内容，

   解决方法必须搭配通配符，但是星号本身就是正则表示法中特殊字符

   ```bash
   # 需要记得 2> /dev/null 表示的是，标准输出错误 不显示在屏幕上
   # 由于该条命令只能搜索文件内容，而不能对目录进行搜索，遇到目录会报错
   [mrcode@study testpw]$ grep '\*' /etc/* 2> /dev/null
   ```

   上述指令只能寻找 /etc 层级下的文件，而不能让子目录下的文件也被搜索到

   ```bash
   # 使用子命令找到 /etc/ 下包含子目录的所有文件
   grep '\*' $(find /etc/ type f) 2> /dev/null
   
   # 可以使用 -l 只列符合条件的文件名
   grep -l '\*' $(find /etc/ type f) 2> /dev/null
   ```

2. 如果文件数量太多，如找的是全系统 ( / )

   ```bash
   [mrcode@study testpw]$ grep '\*' $(find / type f 2> /dev/null)
   -bash: /usr/bin/grep: 参数列表过长
   # 指令内容长度是有限制的，可以通过管线命令以及 xargs 来处理
   # 1. 先用 find 找出文件
   # 2. 用 xargs 将这些文件每次只给 10 个给 grep 作为参数
   # 3. grep 开始搜索文件内容
   find / -type f 2> /dev/null | xargs -n 10 grep '\*'
   ```

3. 从输出的结果看，数据量很大，只需要知道文件名的话，同样可以使用 grep -l 参数

## 情景模拟 2

使用年限命令配合正则表示法建立新指令与新变量。想要建立一个新的指令名为：myip，这个指令能将我系统的 IP 找出来显示。新变量名为 MYIP，该变量可以记录我的 IP

处理格式很简单，可以这样试试看：

1. 首先，使用 ifconfig、sed 与 awk 来取得我们的 IP

   ```bash
   # 这里就是将 ip 前的文字和 ip 后的文字使用 sed 替换成空
   # 注意这里的开头和结尾 .* 表示任意字符出现 0 次多次
   [mrcode@study testpw]$ ifconfig enp0s3 | grep 'inet ' | sed 's/^.*inet //g' | sed 's/ *netmask.*$//g'
   192.168.4.223
   ```

2. 将此命令使用 alias 指定为 myip

   ```bash
   [mrcode@study testpw]$ alias myip="ifconfig enp0s3 | grep 'inet ' | sed 's/^.*inet //g' | sed 's/ *netmask.*$//g'"
   ```

3. 最终，通过变量设置

   ```bash
   [mrcode@study testpw]$ MYIP=$(myip)
   [mrcode@study testpw]$ echo ${MYIP}
   192.168.4.223
   ```

4. 将别名永久生效，需要将 alias 与 MYIP 的设置写入你的 `~/.bashrc` 文件中

## 简答题

1. 在 /etc 下，含有 XYZ 三个字符的任何一个字符的文件就列出来

   ```bash
   grep -l [XYZ] /etc/* 2> /dev/null
   ```

2. 将 /etc/kdump.conf 内容取出后

   ```bash
   1. 去除开头为 # 号的行
   2. 去除空白行
   3. 取出开头为英文字母的行
   4. 统计总行数
   
   [mrcode@study ~]$ grep -v '^#' /etc/kdump.conf | grep -v '^$' | wc -l
   2
   ```

中文维基百科 [ASCII](https://zh.wikipedia.org/w/index.php?title=ASCII)
