# 软件安装：原始码与 Tarball

在第 1 章，linux 是什么中提到了 GNU 计划与 GPL 授权所产生的自由软件与开放源码等概念。不过前面并未提到真正的开放源码是什么信息。

在本章，将通过 LInux 操作系统里的执行文件，来理解什么是可执行的程序，以及了解什么是编译程序。

另外，与程序息息相关的函数库（library）的信息也需要了解下，但是并不是要你成为一个开放源码的设计师，而是希望可以了解如何将开放源码的程序设计、加入函数库的原理、通过编译成为可以执行的 binary program，最后该执行文件可被我们使用的一连串过程

为什么要了解以上信息？因为在 Linux 的世界里面，由于定制化的关系，有时候需要我们自行安装软件，如果你有简单的编译概念，那么将很容易进行软件的安装。甚至在发生软件编译过程中的错误时，你也可以自行做一些简易的修改，而最传统的软件安装过程，就是由原始码编译而来的

所以本章介绍最原始的软件管理方式：使用 Tarball 来安装与升级管理我们的软件

## 开放源码的软件安装与升级简介

在 windows 上安装软件的时候，大多数都是下一步下一步，会很简单，因此在 WIndows 系统上的软件都是一模一样的，也就是说，你无法修改该软件的源码，因此当软件出现 bug 时，或新增/减少一些功能时，就只能等软件开发商来做这些事情。

那么这就体现了 Linux 的优点了，因为 Linux 上面的软件几乎都是经过 GPL 的授权，所以每个软件几乎都提供源代码，并且你可以自行修改该程序代码

那么：

1. 可执行的相关软件与开放源码之间是如何转换的？
2. 不同版本的 Linux 之间能不能使用同一个执行文件？
3. 该执行文件需要由源代码的部分重新进行转换？

以上概念都是需要了解的

## 什么是开放源码、编译程序与可执行文件

在 LInux 系统上，一个文件能否被执行，看的是可执行的哪个权限（具有 x 权限），但是，Linux 系统上真正认识的可执行文件是二进制文件（binary program），例如 `/usr/bin/passwd`、`/bin/touch` 这些二进制程序代码

sheell scripts 并不是一个 binary 程序，它只是利用 shell（例如 bash）这个程序的功能进行一些判断，而最终执行的除了 bash 提供的功能外，认识调用一些已经变异好的二进制程序来执行的

想判定一个文件是否是一个 binary，可以使用在第 6 章提到过的 file 指令

```bash
# 用系统文件测试看看是什么类型
[root@study ~]# file /bin/bash
/bin/bash: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=7e644dee920bc3ba797c38e05383286563712b49, stripped

# 如果是系统提供的 network 呢？
[root@study ~]# file /etc/init.d/network 
/etc/init.d/network: Bourne-Again shell script, ASCII text executable
```

可以看到，如果是 binary 而且是可执行文件的时候，会显示执行文件类别：`ELF 64-bit LSB executable`，同时或说明是否使用 **动态函数库（shared libs）**

如果是一般的 script 则会显示 `ASCII text executable`，`Bourne-Again shell script` 信息则是因为在 script 的第一行申明了 `#!/bin/bash` 的缘故

那么想要做出这样一个 binary program 则需要经过：

1. 编写代码：纯文本的文件
2. 编译：编译为操作系统看得懂的 binary program

举个例子：在 Linux 上最标准的程序语言为 C，使用 C 的语法进行源代码的编写之后，使用 Linux 上标准的 C 语言编译程序 gcc 来编译，就可以制作一个可以执行的 binary program

在编译的过程中还会产生所谓的 **目标文件（Object file）**，这些文件是以 `*.o` 的扩展名存在的。 C 语言的源码文件通常以 `*.c` 作为扩展名。

总之：

- 开放源码：就是程序代码，写给人类看的程序语言，但机器并不认识，所以无法执行
- 编译程序：将程序代码转译成机器能看懂的语言
- 可执行文件：经过编译变成二进制程序后，机器看得懂所以可以执行的文件

## 什么是函数库

简单说，就像是是 JAVA 中的 jar 包，别人开发好的功能，你只要引用，然后调用即可。

函数库分为动态与静态函数库（详细的后面小节讲解）。这里以一个简单的流程图，来示意一个有调用外部函数库的程序执行情况

![image-20200405152313615](http://p6ui.toweydoc.tech:20080/images/stydocs/image-20200405152313615.png)

如果要在程序中加入引用的函数库，就需要上图那样，也就是在编译的过程中，就需要加入函数库的相关设置。

事实上， Linux 的核心提供很多的核心相关函数库与外部参数，这些核心功能在设计硬件的驱动程序的时候是相当有用的信息，这些核心相关的信息大多放在 `/usr/include`、`/usr/lib`、`/usr/lib64` 里面，这些在后续小节来讨论。这里可以这样理解：函数库类似子程序的角色，可以被调用来执行一段功能函数

## 什么是 make 与 configure

使用类似 gcc 编译程序来进行编译的过程并不简单，因为一套软件并不会仅有一个程序，而是有一堆程序代码文件。所以除了每个主程序与子程序均需要写上一个编译过程的指令外，还需要写上最终的链接程序。当程序代码越来越多的时候，光是编译指令的编写就会累死你了，这个时候就可以使用 **make** 指令的相关功能来进行 **编译过程的指令简化**

当执行 make 时，make 会在当时的目录下搜索 Makefile（or makefile）文本文件，里面记录了原始码如何编译的详细信息，make 会自动判断原始码是否经过变动了，而自动更新执行文件，是软件工程师相当好的一个辅助工具

通常软件开发商都会写一个检测程序来检测用户的系统环境，以及该环境是否有软件开发商所需要的其他功能，检测完毕后，**会主动建立这个 Makefile 的规则文件**，通常这个检测程序的文件名为 **configure** 或 **config**

为什么要有以上的检测过程？不同的 distribution 使用的软件可能不同，每个软件所需要的函数库也不相同，同时软件开发商不会仅针对 Linux 开发，而是会针对整个 Unix-Like 做开发，所以必须检测操作系统平台有没有提供合适的编译程序才行，一般来说，检测程序会检测的数据大约有：

- 是否有适合的编译程序可以编译本软件的程序代码
- 是否依据存在本软件所需要的函数库，或其他需要的相依软件
- 操作系统平台是否适合本软件，包括 Linux 的核心版本
- 核心的表头定义文件（hearder include）是否存在（驱动程序必须要的检测）

make 与 configure 运行流程如下图所示

![image-20200405154914626](http://p6ui.toweydoc.tech:20080/images/stydocs/image-20200405154914626.png)

在上图中，你要执行的任务只有两个：先执行 configure 来建立 Makefile，成功之后，再执行 make 来编译

理论上，在 CentOS 7.x 上编译出 binary program 后，不能将它拿到 SuSE 上去执行。由上述描述来看，有太多的不确定因素了

## 什么是 Tarball 软件

Tarball 文件：将软件的所有源码文件以  tar 打包，然后再压缩（通常是 gzip），所以 tarball 文件一般的扩展名为 `*.tar.gz` 或是简写为 `*tgz`。不过，近来由于 bzip2 与 xz 的压缩率较佳，因此它对应的后缀名为 `*.tar.bz2` 、`*.tar.xz` 。

所以，tarball 是一个软件包，将它解压之后，里面的文件通常会有：

- 源代码文件
- 检测程序（可能是 configure 或 config）
- 本软件的简易说明与安装说明（INSTALL 或 README）

其中最重要的是 INSTALL 或 README 文件，通常只要能参考这两个文件，Tarball 软件的安装是很简单的

后续章节会继续介绍 Tarball

## 如何安装与升级软件

安装时因为你需要且系统上没有该软件，为何要升级呢？

- 需要新的功能
- 旧版本的软件上可能有安全方面的漏洞
- 旧版的软件执行效率不佳

那么更新的方法可以分为两大类：

- 直接以原始码通过编译来安装与升级
- 直接以编译好的 binary program 来安装与升级

第一点很简单，直接以 Tarball 在自己的机器上面进行检测、编译、安装与设置。这个过程可以让使用者有很高的自由定制弹性，但是会很麻烦，所以就有 Linux distribution 厂商针对自己平台先进行编译等过程，再将编译好的 binary program 释出，由于我的系统与该 Linux distribution 的环境是相同的，所以可以直接拿来安装，省略了检测与编译等繁杂的过程

这个预先编译好程序的机制存在于很多 distribution，包括有 Red Hat 系统（含 Fedora/CentOS 系列）发展的 RPM 软件管理机制与 yum 在线更新模式；Debian 使用的 dpkg 软件管理机制与 APT 在线更新模式等

那么一个软件的 Tarball 是如何安装的呢？基本流程如下：

1. 将 Tarball 由厂商的网页下载下来
2. 将 Tarball 解开，产生很多的源码文件
3. 开始以 gcc 进行源码的编译（会产生目标文件 object files）
4. 以 gcc 进行函数库、主、子程序的链接，以形成主要的 binary file
5. 将上述的 binary file 以及相关的配置文件安装到自己的主机上

上面的第 3、4 步骤可以通过 make 来简化，所以至少需要 gcc 以及 make 这两个软件在你的 Linux 系统上

## 使用传统程序语言进行编译的简单范例

通过上面的介绍之后，差不多能清楚一点概念了，本章以一个简单的程序范例来说明整个编译的过程

## 单一程序：打印 Hello World

::: tip
请确保你的 Linux 已经安装了 gcc，如果没有安装先参考后续章节的 RPM 或则 yum 方式安装
:::

### 编写程序代码

```bash
[root@study ~]# vim hello.c
#include <stdio.h>

int main(void){
 printf("Hello word\n");
}
```

上面是用 C 语言的语法写成的一个程序文件，第一行的是声明信息

### 开始编译与测试执行

```bash
[root@study ~]# gcc hello.c 
[root@study ~]# ll hello.c a.out 
-rwxr-xr-x. 1 root root 8360 Apr  5 16:24 a.out		# 产生这个文件名
-rw-r--r--. 1 root root   63 Apr  5 16:24 hello.c

[root@study ~]#./a.out 
Hello word
# 执行成功了
```

在默认情况下，以 gcc 编译源码，没有加任何参数的情况下，执行文件的名称会以  a.out 名称出现。a.out 就是编译成功的可执行的 binary program

如果想要产生目标文件（object file）来进行其他的动作，而且自定义执行文件名

```bash
[root@study ~]# gcc -c hello.c 
[root@study ~]# ll hello*
-rw-r--r--. 1 root root   63 Apr  5 16:24 hello.c
-rw-r--r--. 1 root root 1496 Apr  5 16:27 hello.o  # 产生的目标文件

[root@study ~]# ll hello*
-rwxr-xr-x. 1 root root 8360 Apr  5 16:28 hello		# 自定义文件名的可执行文件 -o 
-rw-r--r--. 1 root root   63 Apr  5 16:24 hello.c
-rw-r--r--. 1 root root 1496 Apr  5 16:27 hello.o

[root@study ~]./hello 
Hello word
```

## 主、子程序连接：子程序的编译

如果我们在一个主程序里面又调用了另一个字程序呢？下面的例子中以 thans.c 这个主程序去调用 thanks_2.c 这个子程序

### 编写主、子程序代码

```bash
# 1. 编写主程序
[root@study ~]# vim thanks.c
#include <stdio.h>

int main(void){
 printf("Hello word\n");
 thanks_2();
}

# 2. 编写子程序
[root@study ~]# vim thanks_2.c
#include <stdio.h>

int thanks_2(void){
 printf("Thank you!\n");
}
```

### 程序的编译与连接 Link

```bash
# 2. 将源码编译为颗执行的 binary file
[root@study ~]# gcc -c thanks.c thanks_2.c 
[root@study ~]# ll thanks*
-rw-r--r--. 1 root root   76 Apr  5 16:33 thanks.c
-rw-r--r--. 1 root root 1560 Apr  5 16:35 thanks.o
-rw-r--r--. 1 root root   67 Apr  5 16:34 thanks_2.c
-rw-r--r--. 1 root root 1504 Apr  5 16:35 thanks_2.o
# *.o 文件是编译产生的

[root@study ~]# gcc -o thanks thanks.o thanks_2.o 
[root@study ~]# ll thanks*
-rwxr-xr-x. 1 root root 8424 Apr  5 16:36 thanks
-rw-r--r--. 1 root root   76 Apr  5 16:33 thanks.c
-rw-r--r--. 1 root root 1560 Apr  5 16:35 thanks.o
-rw-r--r--. 1 root root   67 Apr  5 16:34 thanks_2.c
-rw-r--r--. 1 root root 1504 Apr  5 16:35 thanks_2.o

# 3. 执行
[root@study ~]# ./thanks 
Hello word
Thank you!
```

这里你就明白了，为什么要先制作出目标文件了，由于我们的源码文件有时并非只有一个文件，所以无法直接进行编译。这个时候就需要先产生目标文件，再以连结制作为 binary 可执行文件

另外，如果有一天，你更新了 thanks_2.c 这个文件的内容，则你只需要重新编译 thanks_2.c 来产生新的  thanks_2.o ，然后再以连结制作出新的 binary 可执行文件即可。这功能对于庞大的软件功能源码来说会很有用，节省很多的时间

此外，想要程序再执行的时候有比较好的效率，或则是其他的除错功能时，可以在编译的过程里加入适当的参数，如

```bash
# -O 产生优化的参数
[root@study ~]# gcc -O -c thanks.c thanks_2.c

# -Wall 产生更详细的编译过程信息
[root@study ~]# gcc -Wall -c thanks.c thanks_2.c
thanks.c: In function 'main':
thanks.c:5:2: warning: implicit declaration of function 'thanks_2' [-Wimplicit-function-declaration]
  thanks_2();
  ^
thanks.c:6:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
thanks_2.c: In function 'thanks_2':
thanks_2.c:5:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
# 上面的信息为 warning 信息，所以可以忽略也没有关系
```

至于更多的 gcc 额外参数功能，请自行 `man gcc`

## 调用外部函数库：加入连结的函数库

比如要计算数学公式，计算三角函数里面的 sin(90 度角)。要注意的是，大多数程序语言都是使用径度，而不是一般我们计算的角度，180 度角约等于 3.14 径度

```bash
[root@study ~]# vim sin.c
# include <stdio.h>
# include <math.h>

int main(void){
	float value;
	value = sin(3.14 / 2);
	printf("%f\n",value);
}

# 编译
[root@study ~]# gcc sin.c 
```

新版的 GCC 会主动将你所需要的函数库抓进来编译，所以不会出现错误信息，事实上数据函数库使用的是 libm.so 这个函数库，最好在编译的时候将整个函数库链接进来比较好。

函数库放置的地方是系统默认会去找 `/lib`、`/lib64` ，所以无须使用 `-L` 加入搜索的目录，而 libm.so 在编译的写法上，使用的是 `-lm (lib 简写为 l)`，

### 编译时加入额外的函数库连结方式

```bash
[root@study ~]# gcc sin.c -lm -L/lib64
# 重点在 -lm，后面的 -L 是指定搜索的目录
[root@study ~]#./a.out 
1.000000
```

`-lm` 是有意义的，可以拆开成两部分来看：

- `-l`：加入某个函数库（library）
- `m`：libm.so 这个函数库，其中 lib 与扩展名 （.a 或 .so ）不需要写

对于第一行的 `stdio.sh` 则是放在 `/usr/include/stdio.sh` ，如果不在这里的位置，那么久需要指明在哪里

```bash
gcc sin.c -lm -I/usr/include
# include 的路径指明格式为：-I/path
```

通过以上范例，对 gcc 与源码有一定程度的认识了，下面整理下 gcc 的简易使用方法

## gcc 的简易用法（编译、参数与连结）

下面列举几个常用的 gcc 常见的参数用法（详情请 man gcc）

```bash
# 仅将源码编译为目标文件，并不制作连结等功能
gcc -c hello.c
# 会自动产生 hello.o 文件，但是并不会产生 binary 执行文件

# 在编译时，根据作业环境给予优化执行速度
gcc -O hello.c -c
# 会自动产生 hello.o 文件，并进行优化

# 在进行 binary file 制作时，将连结的函数库与相关的路径填入
gcc sin.c -lm -L/lib -I/usr/include
# 该指令常下达在最终连结成 binary file 的时候
# -lm 指 libm.so 或 libm.a 这个函数库文件
# -L 后面接的路径是刚刚那个函数库的搜索目录
# -I 后面接的是源码内的 include 文件所在目录

# 将编译的结果输出到某个特定的文件
gcc -o hello hello.c
# -o 后面接的是要输出的 binary file 文件名

# 在编译的时候，输出较多的信息说明
gcc -o hello hello.c -Wall
# -Wall，程序的编译会变得较为严谨一点，所以警告信息也会显示出来

```

比较常用的如上，另外，通常称 `-Wall` 或 `-O` 这些非必要的参数为旗标 （FLAGS），因为使用的是  C 语言，所以有时候也会简称这些旗标为 CFLAGS，这些变量偶尔会被使用。

在后面的 make 相关用法时，用得较多


## 用 make 进行宏编译

## 为什么要用 make

来看一个案例：执行文档里面包含了 4 个源码文件，分别是 `main.c`、 `haha.c`、 `sin_value.c`、 `cos_value.c`、

- `main.c`：主要目的是让用户输入角度数据与调用其他三个子程序
- `haha.c`：输出一堆有的没有的信息
- `sin_value.c`：计算使用者输入的角度（360）sin 数值
- `cos_value.c`：计算使用者输入的角度（360）cos 数值

`main.c`

```bash
#include <stdio.h>
#define pi 3.14159
char name[15];
float angle;

int main(void)
{
	printf ("\n\nPlease input your name: ");
	scanf  ("%s", &name );
	printf ("\nPlease enter the degree angle (ex> 90): " );
	scanf  ("%f", &angle );
	haha( name );
	sin_value( angle );
	cos_value( angle );
}
```

`haha.c`

```bash
#include <stdio.h>
int haha(char name[15])
{
	printf ("\n\nHi, Dear %s, nice to meet you.", name);
}

```

`sin_value.c`

```bash
#include <stdio.h>
#include <math.h>
#define pi 3.14159
float angle;

void sin_value(void)
{
	float value;
	value = sin ( angle / 180. * pi );
	printf ("\nThe Sin is: %5.2f\n",value);
}

```

`cos_value.c`

```bash
#include <stdio.h>
#include <math.h>
#define pi 3.14159
float angle;

void cos_value(void)
{
	float value;
	value = cos ( angle / 180. * pi );
	printf ("The Cos is: %5.2f\n",value);
}

```

```bash
# 1. 先进行目标文件的编译，最终会有 4 个 *.o 的文件出现
[root@study ~]# gcc -c main.c 
[root@study ~]# gcc -c haha.c 
[root@study ~]# gcc -c sin_value.c 
[root@study ~]# gcc -c cos_value.c 

# 2. 再执行连结称为执行文件，并加入 libm 的函数，产生 man 的执行文件
[root@study ~]# gcc -o man main.o haha.o sin_value.o cos_value.o  -lm

# 3. 执行程序，比如输入姓名，360 度角的角度值来计算
[root@study ~]# ./man 


Please input your name: mrcode		# 输入姓名
	
Please enter the degree angle (ex> 90): 30		# 输入角度


Hi, Dear mrcode, nice to meet you.
The Sin is:  0.50
The Cos is:  0.87
```

可以看到编译指令就变得复杂起来了，如果要重新编译，上述流程还需要重新来一次，很麻烦

可以使用 make 工具简化我们的工作。先建立 makefile 的文件

```bash
# 1. 先编辑 makefile 规则文件，内容只要做出 man 这个执行文件
[root@study ~]# vim makefile
main: main.o haha.o sin_value.o cos_value.o
        gcc -o main main.o haha.o sin_value.o cos_value.o -lm
# 注意第 2 行数据，是按 tab 产生的空格

# 2.尝试使用 makefile 指定的规则进行编译行为
# 先把之前产生的 .o 文件删除
[root@study ~]# rm -f main *.o
[root@study ~]# make          
cc    -c -o main.o main.c
cc    -c -o haha.o haha.c
cc    -c -o sin_value.o sin_value.c
cc    -c -o cos_value.o cos_value.c
gcc -o main main.o haha.o sin_value.o cos_value.o -lm

# 此时 make 会读取 makefile 的内容，并根据内容直接编译相关的文件

# 3. 在不删除任何文件的情况下，重新执行一次编译的动作
[root@study ~]# make
make: `main' is up to date.
# 只会执行更新 update 的动作
```

上面的执行，从命令行输出来看，获取你会觉得 shell script 也可以做到，的确是这样，但是 make 提供了增量编译的机制，不需要你自己去写那么复杂的流程判断了。好处如下：

- 简化编译时所需要下达的指令
- 若在编译完成之后，修改了某个源码文件，则 make 仅会针对被修改了的文件进行编译，其他的 object file 不会变动
- 最后可以依照相依性来更新（update）执行文件

下面针对 makefile 的语法来介绍

## makefile 的基本语法与变量

makefile 的语法多而复杂，可以参考 [GUN 官网文档](http://www.gnu.org/software/make/manual/make.html)，这里仅做一些基本的规则，重点在于你接触源码的时候，不至于恐慌，基本规则如下

```bash
目标（target）：目标文件1 目标文件2
<tab>	 gcc -o 欲建立的执行文件 目标文件1 目标文件2
```

在 makefile 中的规则基本上是：

- `#` 代表批注
- `<tab>` 需要在命令行的第一个字符
- 目标 target 与相依文件（目标文件）之间以 `:` 分割

对上上面那个示例，如果有两个以上的执行动作时，如何做？比如增加一个指令，直接清除所有的目标文件与执行文件

```bash
# 1. 编辑 makefile 来建议新的规则，此规则的目标为 clean
[root@study ~]# vim makefile 
main: main.o haha.o sin_value.o cos_value.o
        gcc -o main main.o haha.o sin_value.o cos_value.o -lm
clean:
        rm -rf main.o haha.o sin_value.o cos_value.o
        
# 2. 以新的目标 clean 测试执行
[root@study ~]# make clean
rm -rf main.o haha.o sin_value.o cos_value.o
```

如此一来，makefile 里就具有至少两个目标，可以单独执行，也可以如下一起组合执行

```bash
[root@study ~]# make clean main
rm -rf main.o haha.o sin_value.o cos_value.o
cc    -c -o main.o main.c
cc    -c -o haha.o haha.c
cc    -c -o sin_value.o sin_value.c
cc    -c -o cos_value.o cos_value.c
gcc -o main main.o haha.o sin_value.o cos_value.o -lm
```

这个时候，你会发现 makefile 中的重复数据很多，可以通过变量来重构

```bash
[root@study ~]# vim makefile 
LIBS = -lm
OBJS = main.o haha.o sin_value.o cos_value.o
main: ${OBJS}
        gcc -o main ${OBJS} ${LIBS}
clean:
        rm -rf main ${OBJS}
# 一定要注意这个 tab 键的语法，不能使用空格替代的！
```

与 bash shell script 的语法有点不太相同，变量的基本语法为：

1. 变量与变量内容以 `=` 隔开，同时两边可以有空格
2. 变量左边不可以有 `<tab>`
3. 变量与变量内容在 `=` 两边不能有 `:`
4. 在习惯上，变量最好以大写字母为主
5. 使用变量时，以 `${变量}、$(变量)`使用
6. 在该 shell 的环境变量是可以被套用的，例如提到的 CFLAGS 这个变量
7. 在指令列模式也可以给予变量

由于 gcc 在编译的行为时，会主动读取 CFLAGS 这个环境变量，所以可以直接在 shell 定义出这个环境变量

```bash
CFLAGS="-Wall" make clean main
# 在 make 进行编译时，会读取 CFLAGS 的变量内容

# 还可以在 makefile 中定义这个变量
```

如果在指令列和 makefile 中都设置了 CFLAGS 变量，而且内容不同，那么哪一个会生效？

1. make 指令列后加上的环境变量为优先
2. makefile 里面指定的环境变量第 2
3. shell 原本具有的环境变量第 3

此外：`$@` 这个特殊的变量，表示目前的目标（target），因此可以修改 makefile 为

```bash
[root@study ~]# vim makefile 
LIBS = -lm
OBJS = main.o haha.o sin_value.o cos_value.o
main: ${OBJS}
        gcc -o $@ ${OBJS} ${LIBS}		
        # 这里的 $@ 就表示是 main 这个字符
clean:
        rm -rf main ${OBJS}
```

## Tarball 的管理与建议

那么接下来我们要知道如何使用具有源码的 Tarball 来建立一个属于自己的软件

Tarball 的安装是可以跨平台的，只是需要的编译程序可能并不相同，例如 Linux 上用 gcc，而 windows 上也有相关的 c 编译程序。

如果万一没有编译成功，可以通过修改小部分的程序代码（通常是因为很小部分的不同）就可以跨平台的移植了

## 使用源码管理软件所需要的基础软件

从源码制作一个 binary program 需要很多软件的支持，包括以下基础的软件：

- gcc 或 cc 等 c 语言编译程序（compiler）

  编译程序也有很多，其中以 GNU 的 gcc 是首选的自由软件编译程序，在 Linux 平台上面发展的软件的源码，原本就是以 gcc 为底来设计的

- 需要 Kernel 提供的 Library 以及相关的 Include 文件

  从前面的源码编译过程，我们知道函数库 library 的重要性，和 include 文件的存在。

  很多软件在发展的时候都是直接取用系统核心提供的函数库与 include 文件，尤其是在驱动程序方面的模块，例如网卡、声卡、USB 等驱动程序在安装的时候，常常需要核心提供相关的信息。

  在 Red Hat 系统中（包含 Fedora、CentOS 等系列），这个核心相关的功能通常都是被包含在 kernel-source 或 kernel-header 这些软件名称中，所以记得安装这些软件

一般来说 Tarball 的安装比较简单，只要顺着开发商提供的 README 与 INSTALL 文件的说明步骤来安装，基本上是很容易的，但是在论坛上还会发现很多人问提示 「没有 gcc 程序」、「无法使用 make」等问题，这些基本上都是以上基础软件没有安装的原因

目前的 Linux distribution 大多已经偏向与桌面计算机的使用（非服务器），所以默认不会安装这些偏向开发的软件，如果你希望未来可以安装一些以 Tarball 方式的软件时，请自行挑选想要安装的软件名称。例如在 CentOS 或死 Red Hat 中，需要选中 Development Tools 以及 Kernel Source Development 等相关字眼的软件群

如果你在安装 Linux 时，没有选择这些软件随机安装，也就是没有 make、gcc 等这些东西，那么可以使用 RPM （下章节讲解）的方式来安装软件，所以只要拿出当初安装 Linux 时的原本光盘，然后以 RPM 来一个一个安装到你的 Linux 主机里面，尤其是现在有 yum ，在线安装更方便了

在 CentOS 中，如果你已经联网的话，那么可以使用下一章会介绍到的 yum，通过 yum 的软件群组安装工功能，可以如下做：

- 安装 gcc 等软件开放工具：`yum groupinstall "Development Tools"`
- 若待安装的软件需要图形接口支持，一般还需要：`yum groupinstall "X Software Development"`
- 若安装的软件较旧，可能需要：`yum groupinstall "Legacy Software Development"`

详细信息请参考后续章节

## Tarball 安装的基本步骤

步骤如下：

1. 取得源码文件：将 tarball 文件在 `/usr/local/src` 目录下解压
2. 取得步骤流程：进入新建立的目录下，查阅 INSTALL 或 README 等相关文件内容（很重要）
3. 相依属性软件安装：根据 INSTALL/README 的内容查看并安装好一些相依的软件（非必要）
4. 建立 makefile：用自动检测程序（configure 或 config）检测作业环境，并建立 Makefile 文件
5. 编译：以 make 程序并使用该目录下的 Makefile 作为参考配置文件，进行 make 编译或其他的动作
6. 安装：以 make 程序，并以 Makefile 作为参数配置文件，根据 install 这个目标（target）的指定来安装到正确的路径

下面简约介绍下大部分的 tarball 软件安装的指令下达方式：

1. `./configure`

   程序开发者提供的一个 scripts 检查程序，并生成 Makefile 文件

2. make clean

   会读取 Makefile 中关于 clean 的工作，该步骤不一定会有，但是希望之星下，因为他可以删除目标文件。至少能保证后续编译出来的 *.o 文件使我们自己机器编译出来的

3. make

   会根据 Makefile 中预设的工作进行编译行为，主要工作是进行 gcc 来将源码编译为可以被执行的 object files。但是这些 object files 通常还需要一些函数库之类的 link 后，才能产生一个完整的执行文件。使用 make 就是将源码便以为可被执行的文件，该执行文件会放到目前所在的目录下，尚未被安装到预定安装的目录中

4. make install

   通常这就是最后的安装步骤了，make 会根据 Makefile 文件里关于 install 的项目，将上一个步骤所编译完成的数据安装到预定的目录中，就安装完成了

以上步骤，只要前一个步骤没有成功，那么后续步骤就无法执行成功的。

如果安装成功，并且是安装在独立的一个目录中，例如 `/usr/local/packages` 目录中，那么你必须手动的将整个软件的 man page 给它写入到 `/etc/man_db.conf`

## 一般 Tarball 软件安装的建议事项（如何移除？升级？）

为什么前一个章节，Tarball 要在 `/usr/local/src` 下解压呢？基本上，在预设的情况下，原本的 Linux distribution 释出安装的软件大多是在 `/usr` 中，而用户自行安装的软件则建议放置 `/usr/local` 中。这是考虑到管理用户所安装软件的便利性

几乎所有的软件都提供联机帮助服务，就是 info 与 man 功能。在默认情况下，man 会搜索 `/usr/local/man` 中的说明文件，因此如果将软件安装在 `/usr/local` 下，那么安装完成后，该软件的说明文件就可以被找到了（笔者疑问：可没有说说明文件说明时候被安装到指定目录的？）

所以，通常建议将自己安装的软件放在 `/usr/local/` 下，至于源码（Tarball）则建议放到 `/usr/local/src` 下

再来看看 Linux distribution 默认的安装软件的路径会用到哪些？这里以 apache 软件来说明：

- `/etc/httpd`：配置文件
- `/usr/lib`：函数库
- `/usr/bin`：执行文件
- `/usr/share/man`：联机帮助文件

会发现软件的内容大致上是放在 etc、lib、bin、man 目录中的。那么通过 tarbal 来安装时，如果是放在预设的 `/usr/local` 中，由于 `/usr/local` 原本默认这几个目录，所以你的数据就会被放在：

- `/usr/local/etc`
- `/usr/local/bin`
- `/usr/local/lib`
- `/usr/local/man`

如果你每个软件都选择在这个默认的路径下安装的话，那么所有的软件文件都将放在这 4 个目录中，那么未来再想要升级或移除的时候，就会比较难以追查文件的来源，而如果在安装的时候选择的是单独目录，例如我将 apache 安装在 `/usr/local/apache` 中，那么你的文件目录就会变成

- `/usr/local/apache/etc`
- `/usr/local/apache/bin`
- `/usr/local/apache/lib`
- `/usr/local/apache/man`

这样一来，移除软件就简单多了，只要将该目录移除就可以了。

当然，实际安装的时候，还需要看该软件的 Makefile 里 install 信息才能知道它的安装情况。因为例如 sendmail 的安装就很麻烦

此种方式虽然有利于软件的移除，但是在执行指令的时候，该指令是否在 PATH 环境变量所记录的路径有关。以上面的 Apache 软件安装为例，`/usr/local/apache/bin` 肯定不在 PATH 里面的，所以执行 apache 的指令，要么使用绝对路径，要么加入到 PATH 中，另外还需要将 `/usr/local/apache/man` 也加入到 man page 搜索的路径中

另外，Tarball 在升级的时候也挺困扰，以 apache 来说明，WWW 服务器为了考虑互动性，所以通常会将 `PHP+MySql+Apache` 一起安装，那么每个软件在安装的时候都有一定的顺序与程序，因为他们之间具有相关性，所以安装时必须要三者同时考虑到他们的函数库与相关的编译参数

假设今天只要升级 PHP呢？有时候因为只涉及动态函数库的升级，那么只要升级 PHP 即可，其他的部分或许影响不大。但是今天如果 PHP 需要重新编译的模块比较多，那么可能会连带的，连 Apahce 这个程序也需要重新编译过才行。所以使用 tarball 确实有它的优点，但是在这方面也确实麻烦

由于 Tarball 在升级与安装上面具有这些特色，即 Tarball 在反安装上面具有比较高的难度（如果你没有好好规划的话），所以为了方便 Tarball 的管理，通常作者会这样建议使用者：

1. 最好将 tarball 的源码数据解压到 `/usr/local/src` 中

2. 安装时，最好安装到 `/usr/local` 这个默认路径下

3. 考虑未来的反安装步骤，最好可以将每个软件单独的安装在 `/usr/local` 下

4. 为安装到单独目录的软件的 man page 加入 man path 搜索

   如果你安装的软件在 `/usr/local/software/` 那么 man page 搜索设置中，可能需要在 `/etc/man_db.conf` 内的 40~50 行左右处，写入如下的一行

   ```bash
   MANPATH_MAP /usr/local/software/bin /usr/local/software/man
   ```

   这样才可以使用 man 来查询该软件的在下文件

::: tip
时至今日，不太需要有 tarball 的安装了。 CentOS/Fedora 有个 RPM 补遗计划，就是俗称的 EPEL 计划，相关说明请参考 [EPEL](https://fedoraproject.org/wiki/EPEL) ，一般学界用到的软件都在里面，除非你要用的软件是专属收费软件，或则是比较冷门的软件，否则都有好心的网友帮我妈打包好了
:::

## 一个简单的范例，利用 ntp 来示范

这里用时间服务器 ntp（network time protocol）软件来测试安装。下载网址请在此 [网页中找到下载包链接](http://www.ntp.org/downloads.html) ，本次使用 `http://www.eecis.udel.edu/~ntp/ntp_spool/ntp4/ntp-4.2/ntp-4.2.8p14.tar.gz` 这个版本。

假设我对这个软件的要求如下：

- 假设 `ntp4.*.*.tar.gz` 文件放到 `/root` 目录下
- 源码解压在 `/usr/local/src` 下
- 安装到 `/usr/local/ntp` 目录中

​    

解压文件，并阅读 README/INSTALL 文件

```bash
[root@study ~]# cd /usr/local/
[root@study local]# tar -zxv -f /root/ntp-4.2.8p14.tar.gz
[root@study local]# cd ntp-4.2.8p14/
[root@study ntp-4.2.8p14]# vi INSTALL
# 查看安装说明，使用 set nu 显示行号
# 然后阅读 28 ~ 54 行的安装步骤，大约就是如下的内容
   28 The simplest way to compile this package is:
   29 
   30   1. `cd' to the directory containing the package's source code and type
   31      `./configure' to configure the package for your system.  If you're
   32      using `csh' on an old version of System V, you might need to type
   33      `sh ./configure' instead to prevent `csh' from trying to execute
   34      `configure' itself.
   35 
   36      Running `configure' takes a while.  While running, it prints some
   37      messages telling which features it is checking for.
   38 
   39   2. Type `make' to compile the package.
   40 
   41   3. Optionally, type `make check' to run any self-tests that come with
   42      the package.
   43 
   44   4. Type `make install' to install the programs and any data files and
   45      documentation.
   46 
   47   5. You can remove the program binaries and object files from the
   48      source code directory by typing `make clean'.  To also remove the
   49      files that `configure' created (so you can compile the package for
   50      a different kind of computer), type `make distclean'.  There is
   51      also a `make maintainer-clean' target, but that is intended mainly
   52      for the package's developers.  If you use it, you may have to get
   53      all sorts of other programs in order to regenerate files that came
   54      with the distribution.
```

检查 configure 支持的参数，并实际建立 makefile 规则文件

```bash
[root@study ntp-4.2.8p14]# ./configure --help | more
`configure' configures ntp 4.2.8p14 to adapt to many kinds of systems.

Usage: ./configure [OPTION]... [VAR=VALUE]...

To assign environment variables (e.g., CC, CFLAGS...), specify them as
VAR=VALUE.  See below for descriptions of some of the useful variables.
有很多参数，下面列出来比较重要的选项
--prefix=PREFIX         install architecture-independent files in PREFIX
                          [/usr/local]
--enable-all-clocks     + include all suitable non-PARSE clocks:
--enable-parse-clocks   - include all suitable PARSE clocks:

[root@study ntp-4.2.8p14]# ./configure --prefix=/usr/local/ntp --enable-all-clocks --enable-parse-clocks
...
checking for gcc..gcc				# 找到了 gcc 编译程序
...
configure: creating ./config.status
config.status: creating libevent.pc
config.status: creating libevent_openssl.pc
config.status: creating libevent_pthreads.pc
config.status: creating Makefile		# 创建了一个 Makefile
config.status: creating config.h
config.status: creating evconfig-private.h
config.status: evconfig-private.h is unchanged
config.status: executing depfiles commands
config.status: executing libtool commands
```

一般来说 configure 设置参数比较重要的就是 `--prefix=PREFIX`了，后面指定了该软件未来要安装到的目录

最后开始编译与安装

```bash
[root@study ntp-4.2.8p14]# make clean; make
[root@study ntp-4.2.8p14]# make check
...
============================================================================
Testsuite summary for ntp 4.2.8p14
============================================================================
# TOTAL: 1
# PASS:  1
# SKIP:  0
# XFAIL: 0
# FAIL:  0
# XPASS: 0
# ERROR: 0
============================================================================
# 通过 check 后，会列出一个清单结果，这里是表示都成功了
[root@study ntp-4.2.8p14]# make install
# 安装成功后，就可以看到 ntp 目录下安装好的文件了
[root@study ntp]# cd /usr/local/ntp
[root@study ntp]# ll
total 0
drwxr-xr-x. 2 root root 189 Apr  6 03:49 bin
drwxr-xr-x. 2 root root   6 Apr  6 03:49 libexec
drwxr-xr-x. 2 root root   6 Apr  6 03:49 sbin
drwxr-xr-x. 5 root root  39 Apr  6 03:49 share
```

## 利用 patch 更新源码

所谓更新源码，通常是某一段代码有问题，因此通常只是更新部分文件的小部分内容。

好处则是：没有变动的文件的目标文件（object file）不需要重新编译，变动过的文件可以利用 make 来自动 update，如此一来，原先的设置（makefile 文件里面的规则）将不需要重新改写或检测，可以节省很多的宝贵时间

可以用 diff 指令将两个文件的差异性列出来，再以相关的指令来将旧版的文件更新，这是可以的，通常很多软件开发商在更新了源码之后，几乎都会放出所谓的 patch file，也就是直接将源码 update 的一个方式，使用 patch 指令来完成。

关于 diff 与 patch 的基本用法在第 11 章已经讲过了。下面通过一个简单的例子来讲解；之前章节的计算函数的例子，相关文件如下

### main-0.1 版本

```bash
[root@study main-0.1]# ll
total 20
-rw-r--r--. 1 root root 184 Apr  6 04:01 cos_value.c
-rw-r--r--. 1 root root 101 Apr  6 04:01 haha.c
-rw-r--r--. 1 root root 291 Apr  6 04:01 main.c
-rw-r--r--. 1 root root 142 Apr  6 04:02 Makefile
-rw-r--r--. 1 root root 186 Apr  6 04:02 sin_value.c
```

注意：以下文件，可能是由于复制过程中的编码问题，会导致部分与 patch 中的文件内容不一致，从而导致 patch 过程失败，请直接下载以下链接中的包，并解压到 `/root/` 下

- wget http://linux.vbird.org/linux_basic/0520source/main-0.1.tgz

- wget http://linux.vbird.org/linux_basic/0520source/main_0.1_to_0.2.patch

  下载后，修改文件名为 `main-0.1-to-0.2.patch`

`main.c`

```bash
#include <stdio.h>
#define pi 3.14159
char name[15];
float angle;

int main(void)
{
	printf ("\nversion 0.1");
	printf ("\n\nPlease input your name: ");
	scanf  ("%s", &name );
	printf ("\nPlease enter the degree angle (ex> 90): " );
	scanf  ("%f", &angle );
	haha( name );
	sin_value( angle );
	cos_value( angle );
}
```

`haha.c`

```bash
#include <stdio.h>
int haha(char name[15])
{
	printf ("\n\nHi, Dear %s, nice to meet you.", name);
}
```

`sin_value.c`

```bash
#include <stdio.h>
#include <math.h>
#define pi 3.14159
float angle;

void sin_value(void)
{
        float value;
        value = sin ( angle / 180. * pi );
        printf ("\nThe sin(%f) is: %5.2f\n",angle, value);
}
```

`cos_value.c`

```bash
#include <stdio.h>
#include <math.h>
#define pi 3.14159
float angle;

void cos_value(void)
{
	float value;
	value = cos ( angle / 180. * pi );
	printf ("The Cos is: %5.2f\n",value);
}
```

`Makefile`

```bash
# This make file is a test rule file
# # Version 0.1 2009/06/06
LIBS = -lm
OBJS = main.o haha.o sin_value.o cos_value.o
main: ${OBJS}
        gcc -o main ${OBJS} ${LIBS}
clean:
        rm -f main ${OBJS}
```

记得调整上面使用 tab 的语法部分

### 由 0.1 升级到 0.2 的 patch file

`main-0.1-to-0.2.patch`

```bash
diff -Naur main-0.1/cos_value.c main-0.2/cos_value.c
--- main-0.1/cos_value.c	2015-09-04 14:46:59.200444001 +0800
+++ main-0.2/cos_value.c	2015-09-04 14:47:10.215444000 +0800
@@ -7,5 +7,5 @@
 {
 	float value;
 	value = cos ( angle / 180. * pi );
-	printf ("The Cos is: %5.2f\n",value);
+	printf ("The cos(%f) is: %5.2f\n",angle, value);
 }
diff -Naur main-0.1/main.c main-0.2/main.c
--- main-0.1/main.c	2009-06-12 00:39:38.000000000 +0800
+++ main-0.2/main.c	2009-06-12 00:45:38.000000000 +0800
@@ -5,7 +5,7 @@
 
 int main(void)
 {
-	printf ("\nversion 0.1");
+	printf ("\nversion 0.2");
 	printf ("\n\nPlease input your name: ");
 	scanf  ("%s", &name );
 	printf ("\nPlease enter the degree angle (ex> 90): " );
diff -Naur main-0.1/Makefile main-0.2/Makefile
--- main-0.1/Makefile	2009-06-12 00:34:53.000000000 +0800
+++ main-0.2/Makefile	2009-06-12 00:42:39.000000000 +0800
@@ -1,8 +1,12 @@
 # This make file is a test rule file
-# Version 0.1 2009/06/06
+# Version 0.2 2009/06/11
 LIBS = -lm
 OBJS = main.o haha.o sin_value.o cos_value.o
 main: ${OBJS}
 	gcc -o main ${OBJS} ${LIBS}
 clean:
 	rm -f main ${OBJS}
+install:
+	cp -a main /usr/local/bin
+uninstall:
+	rm -f /usr/local/bin/main
diff -Naur main-0.1/sin_value.c main-0.2/sin_value.c
--- main-0.1/sin_value.c	2015-09-04 14:46:52.286444001 +0800
+++ main-0.2/sin_value.c	2015-09-04 14:47:17.665444020 +0800
@@ -7,5 +7,5 @@
 {
 	float value;
 	value = sin ( angle / 180. * pi );
-	printf ("\nThe Sin is: %5.2f\n",value);
+	printf ("\nThe sin(%f) is: %5.2f\n",angle, value);
 }
```

把这目录和文件放到 root 目录下

```bash
drwxr-xr-x. 2 root   root         88 Apr  6 04:11 main-0.1
-rw-r--r--. 1 root   root       1538 Apr  6 04:11 main-0.1-to-0.2.patch
```

在 0.1 版本中，有 main 与 clean 两个目标功能。而 0.2 版本则增加了 install 与 uninstall 的规则与设置。下面来进行升级

### 测试旧版程序的功能

```bash
[root@study main-0.1]# make clean main   
rm -f main main.o haha.o sin_value.o cos_value.o
cc    -c -o main.o main.c
cc    -c -o haha.o haha.c
cc    -c -o sin_value.o sin_value.c
cc    -c -o cos_value.o cos_value.c
gcc -o main main.o haha.o sin_value.o cos_value.o -lm
[root@study main-0.1]# ./main 

version 0.1

Please input your name: mrcode

Please enter the degree angle (ex> 90): 45


Hi, Dear mrcode, nice to meet you.
The Sin is:  0.71
The Cos is:  0.71
```

与之前的结果类似，但是如果你下达 make install 时，系统会告知没有 install 的 target，如何更新到 0.2 版本呢？

### 查阅 patch file 内容

```bash
[root@study ~]# vim main-0.1-to-0.2.patch 
diff -Naur main-0.1/cos_value.c main-0.2/cos_value.c
--- main-0.1/cos_value.c	2015-09-04 14:46:59.200444001 +0800
+++ main-0.2/cos_value.c	2015-09-04 14:47:10.215444000 +0800
```

`diff -Naur main-0.1/cos_value.c main-0.2/cos_value.c`

表示使用 diff 去比较时，比较的两个文件路径，该路径非常重要，因为 patch 的基本语法如下

```bash
patch -p 数字 < patch_file

-p： 与 patch_file 里列出的文件名有关的信息。假如 patch_file 里面累出的文件名有关的信息，假如第一行是写的 `*** /home/guest/example/expatch.old`

那么当下达 patch -p0 < patch_file 时，更新的文件是 /home/guest/example/expatch.old,
如果下达  patch -p1 < patch_file 时，更的文件是 home/guest/example/expatch.old
如果下达  patch -p4 < patch_file 时，更新的是 expatch.old
也就是说 -pxx xx 表示是拿掉几个斜线的意思

那么上面比较的文件是在 main-0.1/xxx 与 main-0.2/xxx 所以，如果你是在 main-0.1 下，并且想要处理更新时，就需要拿掉一个目录，因为并没有 main-0.2 的存在，我们是在当前的目录进行更新的，因此需要使用 -p1 才对
```

### 更新源码，并重新编译程序

```bash
[root@study main-0.1]# patch -p1 < ../main-0.1-to-0.2.patch 
patching file cos_value.c
patching file main.c
patching file Makefile
patching file sin_value.c
# 请注意，目前所在的目录在 main-0.1 ，注意与 patch 文件的相对路径
# 虽然有 5 个文件，但是只有 4 个文件有修改过，上面显示有修改过的文件

[root@study main-0.1]# make clean main
rm -f main main.o haha.o sin_value.o cos_value.o
cc    -c -o main.o main.c
cc    -c -o haha.o haha.c
cc    -c -o sin_value.o sin_value.c
cc    -c -o cos_value.o cos_value.c
gcc -o main main.o haha.o sin_value.o cos_value.o -lm
[root@study main-0.1]# ./main 

version 0.2

Please input your name: mrcode

Please enter the degree angle (ex> 90): 45


Hi, Dear mrcode, nice to meet you.
The sin(45.000000) is:  0.71
The cos(45.000000) is:  0.71

[root@study main-0.1]# make install
cp -a main /usr/local/bin
# 可以看到，把执行程序复制到了 bin 下，所以就可以不加绝对路径运行了
[root@study main-0.1]# main
[root@study main-0.1]# make uninstall
rm -f /usr/local/bin/main
```

这个就是利用了 diff 和 patch 指令来完成的源码更新，然后重新编译安装的效果和流程。

如果你 patch 错误呢？可以通过 `patch -R < ../main-0.1-to-0.2.patch` 将已经更新过的还原。（笔者在复制笔记上的文件到虚拟机文件的时候，不知道哪里有问题，导致前 4 个文件可以 patch 成功，但是第 4 个文件显示失败，这种情况下，就可以通过这样的指令还原回去）

一个问题：如果有一个很旧版本的软件，该软件已经更新到最新版本，例如核心，我可以使用 patch file 来更新吗？

答：首先要确认有释放出 patch file 才行，以 kernel 2.2.xx 与 2.4.xx 来说，基本上的架构已经不同了，所以两者无法以 patch file 来更新的。不过 2.4.xx 与 2.4.yy 就可以。不过，因为 kernel 每次推出的 patch 文件都是针对前一个版本而已，假设你的内核是 kernel 2.4.20 要升级大 2.5.26，那么中间有 5 个文件，需要按顺序更新才可以。但是如果有朋友帮你对比过 2.4.20 与 2.4.26，那么你直接使用该 patch file 来直接一次更新也可以


## 函数库的管理

在 Linux 操作系统中，函数库是很重要的一个项目，因为很多软件之间都会互相取用彼此提供的函数库来进行特殊功能的运行，所以很函数库的利用是很重要的。

不过函数库又按照是否被编译到程序内部而分为动态与静态函数库，他们有什么差异呢？

## 动态与静态函数库

### 静态函数库的特色

- 扩展名：`.a`

  通常扩展名为 `libxxx.a` 类型

- 编译行为：

  在编译时会直接整合到执行程序中，所以利用静态函数库编译成的文件会比较大

- 独立执行的状态：

  最大优点就是编译成功的可执行文件可以独立执行，而不需要再向外部要求读取函数库的内容

- 升级难易度

  由于全部打包到执行文件中，因此若函数库升级，整个执行文件必须要重新编译

### 动态函数库的特色

- 扩展名：`.so`

  通常为 `libxxx.so`

- 编译行为

  动态函数库在编译的时候，在程序里面只有一个「指向（Pointer）」位置而已。在实际运行时才会去读取函数库来使用，因此编译后的执行文件相对小很多

- 独立执行的状态

  不能被独立执行，因为所指向的函数库必须要存在才行，而且函数库「所在的目录也不能改变」，因为可执行文件里面仅有「指向」，也就是在需要使用函数库时，程序会主动去某个路径下读取，

- 升级难易度

  相对来说，执行文件可能不需要重新编译，由于有指向，只需要更新某个函数库即可

目前的 Linux distribution 比较倾向于使用动态函数库，上面已经提到过了，好处多多

绝大多数的函数库都放在 `/lib64`、`/lib` 目录下，此外， Linux 系统里很多的函数库其实 kernel 就提供了，那么 kernel 的函数库是放在 `/lib/modules` 里面的。

注意：不同版本核心提供的函数库差异有可能差异很大，不要版本混用函数库

## ldconfig 与 `/etc/ld.so.conf`

目前我们的 Linux 大多数将函数库做成动态函数库后，在运行时有没有办法改善函数库的读取效率？将常用到的动态函数库先加载到内存中，如此一来当软件要调用动态函数库时，就不需要去硬盘中读取了，这个时候就需要用到 Idconfig 与 `/etc/id.so.conf`

如何将动态函数库加载到高速缓存中呢？

1. 首先，必须要在 `/etc/ld.so.conf` 里写下「想要读入高速缓存中的动态函数库所在的目录」
2. 利用 Idconfig 程序将 `/etc/ld.so.conf` 的资料读取到内存中
3. 同时也将数据记录一份在 `/etc/ld.so.cache` 文件中

事实上，Idconfig 还可以用来判断动态函数库的链接信息

```bash
ldconfig [-f conf] [-C cache]
ldconfig [-p]

选项与参数
	-f conf：conf 指某个文件名，含义是使用 conf 作为 libaray 函数库的取得路径，而不以 `/etc/ld.so.conf` 作为默认值
	-C cache：自定义 cache 文件的路径
	-p：列出目前的所有函数库资料内容（在 /etc/ld.so.cache 内的资料） 

```

```bash
# 范例 1：假设我的 Mariadb 数据库函数库在 /usr/lib64/mysql 中，如何读入 cache
[root@study ~]# vim /etc/ld.so.conf.d/mrcode.conf
/usr/lib64/mysql			# 仅增加一行数据
[root@study ~]# ldconfig
# 执行后不会显示任何信息的

# 就发现找到了我们刚刚加载的
[root@study ~]# ldconfig -p | grep mysql
        libmysqlclient.so.18 (libc6,x86-64) => /usr/lib64/mysql/libmysqlclient.so.18
```

这做了之后，可以加快函数库读取的效率。在某些时候，你可能会自行加入某些 Tarball 安装的动态函数库，而想要这些动态函数库的相关链接可以被读入到缓存中，这个时候就可以像面那样写到 .conf 文件中

### 程序的动态函数库解析：ldd

可以通过 ldd 判断某个可执行的 binary 文件含有哪些动态函数库。

```bash
ldd [-vdr] [filename]

选项与参数：
	-v：列出所有内容信息
	-d：重新将资料有遗失的 link 显示
	-r：将 ELF 有关的错误内容显示
```

实践练习

```bash
# 范例 1：找出 /usr/bin/passwd 文件的函数库数据
[root@study ~]# ldd /usr/bin/passwd 
	linux-vdso.so.1 =>  (0x00007ffe3234e000)
	libuser.so.1 => /lib64/libuser.so.1 (0x00007f320cce7000)
	libgobject-2.0.so.0 => /lib64/libgobject-2.0.so.0 (0x00007f320ca96000)
	libglib-2.0.so.0 => /lib64/libglib-2.0.so.0 (0x00007f320c780000)
	libpopt.so.0 => /lib64/libpopt.so.0 (0x00007f320c576000)
	libpam.so.0 => /lib64/libpam.so.0 (0x00007f320c367000)	# PAM 模块
	libpam_misc.so.0 => /lib64/libpam_misc.so.0 (0x00007f320c163000)
	libaudit.so.1 => /lib64/libaudit.so.1 (0x00007f320bf3a000)
	libselinux.so.1 => /lib64/libselinux.so.1 (0x00007f320bd13000)	# SELinux
	libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f320baf7000)
	libc.so.6 => /lib64/libc.so.6 (0x00007f320b729000)
	libgmodule-2.0.so.0 => /lib64/libgmodule-2.0.so.0 (0x00007f320b525000)
	libcrypt.so.1 => /lib64/libcrypt.so.1 (0x00007f320b2ee000)
	libpcre.so.1 => /lib64/libpcre.so.1 (0x00007f320b08c000)
	libffi.so.6 => /lib64/libffi.so.6 (0x00007f320ae84000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00007f320ac80000)
	libcap-ng.so.0 => /lib64/libcap-ng.so.0 (0x00007f320aa7a000)
	/lib64/ld-linux-x86-64.so.2 (0x00007f320d10d000)
	libfreebl3.so => /lib64/libfreebl3.so (0x00007f320a877000)
	
# 之前一直在说 passwd 有使用到 pam 模块，怎么知道的？
# 上面通过 ldd 就知道了，使用了 libpam.so 函数库

# 范例 2：找出 /lib64/libc.so.6 这个函数库的相关其他函数库
[root@study ~]# ldd -v /lib64/libc.so.6 
	/lib64/ld-linux-x86-64.so.2 (0x00007fbe6ee0f000)
	linux-vdso.so.1 =>  (0x00007ffe450fa000)

	Version information:  # 使用 -v 选项，显示其他版本信息
	/lib64/libc.so.6:
		ld-linux-x86-64.so.2 (GLIBC_2.3) => /lib64/ld-linux-x86-64.so.2
		ld-linux-x86-64.so.2 (GLIBC_PRIVATE) => /lib64/ld-linux-x86-64.so.2
```

未来如果你常常升级安装 RPM 软件时（下一章会介绍），应该常常会发现那个「相依属性」的问题，可以先用 ldd 观察「相依函数库」之间的相关性

如上，检查了 `libc.so.6` 这个函数库，结果发现他还与 `ld-linux-x86-64.so.2 (GLIBC_2.3)` 有关，就可以了解下那个文件到底是什么软件的函数库


## 检验软件的正确性

在网络上下载软件时，由于黑客无处不在，那么你这么保证你下载的文件是原版官方放出来的文件？这就需要通过 **每个文件独特的指纹验证数据了**

每个文件的内容与文件大小都不同，如果一个文件被修改之后，必然会有部分信息不一样，利用这个特性，可以使用 MD5/sha1 或更严密的 sha256 等指纹验证机制来判断该文件是否被更改过

## md5sum、sha1sum、sha256sum

目前有多重机制可以计算文件的指纹码，我们选择使用较为广泛的 MD5、SHA1、SHA256 加密机制来处理。

这里使用前一小节下载的 NPT 软件，来测试。在 NTP 下载页面上，提供了一个 md5 文件的下载，把这个对应版本的 md5 文件下载下来，里面就写着他的指纹码

```bash
mrcode:Downloads mrcode$ cat ntp-4.2.8p14.tar.gz.md5
MD5 (ntp-4.2.8p14.tar.gz) = 783edaf1d68ddf651bde64eda54a579d
```

如果如下的方式获取我们下载的 ntp 软件的指纹码，语法为

```bash
md5sum/sha1sum/sha256sum [-bct] filename
md5sum/sha1sum/sha256sum [--status|--warn] --check filename

-b：使用 binary 的读取方式，默认为 Windows/DOS 文件形态的读取方式
-c：检验文件指纹
-t：以文字形态来读取文件指纹
```

```bash
# 范例 1：获取刚刚 NTP 软件的指纹码
[root@study ~]# md5sum ntp-4.2.8p14.tar.gz 
783edaf1d68ddf651bde64eda54a579d  ntp-4.2.8p14.tar.gz
# 使用此指纹码对比刚刚官网下载下来的指纹码是否相同
```

你可以利用此特性将一些重要文件进行指纹数据库的建立，这样就能知道文件是否被修改过了

```bash
# 将多个文件生成指纹码，并写入文件中
[root@study ~]# md5sum /etc/group /etc/passwd >> data.md5
[root@study ~]# cat data.md5 
b75dbd8dc79305ad77c798ba1c9289e2  /etc/group
a60de527e76f0d5b31b0114098c8072a  /etc/passwd

# 校验指纹码是否匹配
[root@study ~]# md5sum -c data.md5                       
/etc/group: OK
/etc/passwd: OK
```

## 重点回顾

- 源码其实大多是纯文本文件，需要通过编译程序的编译动作后，才能制作出 Linux 系统能够认识的可执行的 binary file
- 开放源码可以加速软件的更新速度，让软件效率更快、漏洞修补更实时
- 在 Linux 系统中，最标准的 C 语言编译程序为 gcc
- 在编译的过程中，可以通过其他软件提供的函数库来使用该软件的相关机制与功能
- 为了简化编译过程当中的服务的指令输入，可以通过 make 与 makefile 规则定义，来简化程序的更新、编译、连结等动作
- Tarball 为使用 tar 与 gzip/bzip2/xz 压缩功能所打包与压缩的，具有源码文件
- 一般而言，要使用 Tarball 管理 Linux 系统上的软件，最好需要 gcc、make、autoconfig、kernel source、kernel header 等前置软件才行，所以在安装 Linux 之初，最好能够选择 Software devlopment 以及 kernel devlopment 之类的群组软件
- 函数库又动态函数库与静态函数库，动态函数库在升级上具有较佳的优势。动态函数库的扩展名为 `*.so`，静态为 `*.a`
- patch 的主要功能在更新源码，所以更新源码之后，还需要进行重新编译的动作
- 可以利用 ldconfig 与 `/etc/ld.so.conf` 和 `/etc/ld.so.conf.d/*.conf` 来制作动态函数库的连结与缓存
- 通过 md5、sha1、sha256 的编码可以判断下载的文件是否为原厂所释放出来的文件

## 本章习题

请按照以下的方式来建立你的系统重要文件指纹膜，并每日对比此重要工作

1. 将 `/etc/{passwd,shadow,group}` 以及系统上所有的 SUID/SGID 文件建立文件列表，命名为 important.file

   ```bash
   [root@study ~]# ls /etc/{passwd,shadow,group} > important.file
   # 将 SUID/SGID 文件追加写入到文件中
   [root@study ~]# find /usr/sbin/ /usr/bin -perm /6000 >> important.file 
   ```

2. 通过这个文档名列表，建立 md5.checkfile.sh 脚本，并将该指纹码文件 finger1.file 设置为不可修改属性

   ```bash
   [root@study ~]# vim md5.checkfile.sh
   #!/bin/bash
   for filename in $(cat /root/important.file)
   do
   	md5sum $filename >> finger1.file
   done
   
   [root@study ~]# sh md5.checkfile.sh
   [root@study ~]# chattr +i finger1.file
   ```

3. 通过相同的机制去建立后续的分析数据为 `finger_new.file` ，并将两者进行对比，若有问题则提供 email 给 root 查询

   ```bash
   [root@study ~]# vim md5.checkfile.sh
   #!/bin/bash
   if [ "$1" === "new" ]; then
     for filename in $(cat /root/important.file)
     do
       md5sum $filename >> finger1.file
     done
     echo "New file finger1.file is created."
     exit 0
   fi
   
   if [ ! -f finger1.file ]; then
   	echo "file: finger1.file NOT exist."
   	exit 1
   fi
   
   [ -f finger_new.file ] && rm finger_new.file
   for filename in $(cat /root/important.file)
     do
       md5sum $filename >> finger_new.file
     done
   fi
   
   testing=$(diff finger1.file finger_new.file)
   if [ "$testing" != "" ]; then
   	diff finger1.file finger_new.file | mail -s 'finger trouble..' root
   fi
   
   [root@study ~]# vim /etc/crontab
   30 2 * * * root cd /root; sh md5.checkfile.sh
   ```

   以上脚本则可以自动分析这些文件是否有改动

